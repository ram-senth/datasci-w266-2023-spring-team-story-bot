{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wHUaO6-oCKak",
   "metadata": {
    "id": "wHUaO6-oCKak"
   },
   "source": [
    "# Manual Annotation\n",
    "This notebook is for running the manual annotation. It supports two activities:\n",
    "-  Identifying the best response in each batch of generated text.\n",
    "- Annotating the best response, as identified by the model, from each batch.\n",
    "- Annotating the best response, as identified manually in the above step from each batch.\n",
    "\n",
    "The first step of manually identifying the best response should be done just once by one person while the next step should be done individually by each annotator. Before getting started, ensure that the annotator name is set correctly.\n",
    "\n",
    "Pre-requisites:\n",
    "- The annotation input file, generated through the inferencing.ipynb notebook, must be available in GDRIVE_BASE location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97nY_nL9CeiJ",
   "metadata": {
    "id": "97nY_nL9CeiJ"
   },
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "egOvt-Oq0M2J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1163,
     "status": "ok",
     "timestamp": 1681142634783,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "egOvt-Oq0M2J",
    "outputId": "a674b1ec-7c45-42c7-994d-9b3b568a14f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "common.__version__: 1.4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "GDRIVE_BASE = 'drive/MyDrive/MIDS/w266/project/'\n",
    "ANNOTATOR='ram'\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "sys.path.insert(0, GDRIVE_BASE)\n",
    "\n",
    "import common\n",
    "\n",
    "print(f'common.__version__: {common.__version__}')\n",
    "# tuning_configs = common.create_configs(GDRIVE_BASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RIepPh55dtNF",
   "metadata": {
    "id": "RIepPh55dtNF"
   },
   "source": [
    "# Best in Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "pTF_5WE-d7rv",
   "metadata": {
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1681143987034,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "pTF_5WE-d7rv"
   },
   "outputs": [],
   "source": [
    "def is_completed(batch):\n",
    "  return len(batch[batch.human_top_score == True]) > 0\n",
    "\n",
    "def mark_best(ignore_completed=False, save_each_step=True):\n",
    "  # Load the annotation input\n",
    "  if ignore_completed:\n",
    "    # Load from prevously saved work.\n",
    "    df_results = pd.read_csv(common.annotation_with_best_loc(GDRIVE_BASE))\n",
    "  else:\n",
    "    # Load from the original annotation input.\n",
    "    df_results = pd.read_csv(common.annotation_input_loc(GDRIVE_BASE))\n",
    "    # Add a new column to hold the best in batch flag.\n",
    "    df_results['human_top_score'] = False\n",
    "  num_batches = df_results.batch_id.max()\n",
    "  batch_size = int(df_results.shape[0] / num_batches)\n",
    "\n",
    "  # Random order of batches.\n",
    "  batch_ids = np.arange(num_batches)\n",
    "  np.random.shuffle(batch_ids)\n",
    "  with tqdm(total=num_batches, unit='item', unit_scale=True) as pbar:\n",
    "    for cur_batch_id in batch_ids:\n",
    "      # Adjust for batch ids starting from 1.\n",
    "      cur_batch_id = cur_batch_id + 1\n",
    "      batch = df_results[df_results.batch_id == cur_batch_id]\n",
    "      if len(batch) != batch_size:\n",
    "        # We should never get here something is wrong.\n",
    "        raise Exception(f'Batch {cur_batch_id} has {len(batch)} items but expecting {batch_size} items.')\n",
    "      if is_completed(batch):\n",
    "        print(f'Skipping batch {cur_batch_id} as it is already completed.')\n",
    "      else:\n",
    "        pbar.set_postfix(batch_id=cur_batch_id, prompt=batch.prompt.iloc[0][0:10] + '...', refresh=True)\n",
    "        # Display the batch and get user's choice pick the best.\n",
    "        indices = {}\n",
    "        print(f'PROMPT: {batch.prompt.iloc[0]}')\n",
    "        i = 1\n",
    "        for index, row in batch.iterrows():\n",
    "          print(f'{i}. {row[\"generated\"]}')\n",
    "          indices[i] = index\n",
    "          i = i+1\n",
    "        \n",
    "        user_opt = -1\n",
    "        msg = f'Enter 1 to {batch_size} or \"quit\"'\n",
    "        quit = False\n",
    "        while user_opt == -1:\n",
    "          try:\n",
    "            user_input = input(f'{msg}: ')\n",
    "            if user_input == 'quit':\n",
    "              quit = True\n",
    "              break\n",
    "            user_opt = int(user_input)\n",
    "            if user_opt in indices:\n",
    "              df_results.loc[indices[user_opt],'human_top_score'] = True\n",
    "              if save_each_step:\n",
    "                df_results.to_csv(common.annotation_with_best_loc(GDRIVE_BASE), index=None)\n",
    "            else:\n",
    "              print(msg)\n",
    "              user_opt = -1\n",
    "          except ValueError:\n",
    "            print(msg)\n",
    "            user_opt = -1      \n",
    "        pbar.update(1)\n",
    "        if quit:\n",
    "          break\n",
    "    df_results.to_csv(common.annotation_with_best_loc(GDRIVE_BASE), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ZqiupvHh7VmF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370,
     "referenced_widgets": [
      "487be0e372fd463bac6f8e8d8fb92696",
      "07ecf2ae8139480fa9fb41a0ae4441e5",
      "42311802efb645bfbb03b34a79d83c0e",
      "0289b6e67cb04e259aa182fff635e13a",
      "af6ad6a95cd442c3823fe8a4ac95a5ef",
      "c5628f1605494a07a1d6cb35aafc3a80",
      "5e055f20edec48d0926aac9b3cb41b7d",
      "3f54b679c57c472ba283dd7da4db385a",
      "304349226f3a4e7ba604a961902e249f",
      "9114f9dcf39c477b9d2680ed48b62644",
      "4fe640c9df474dd2a23bb5f9b2df0e81"
     ]
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681144049686,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "ZqiupvHh7VmF",
    "outputId": "46117efa-b0ad-467f-fb6b-dbba5affa163"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487be0e372fd463bac6f8e8d8fb92696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/18.0 [00:00<?, ?item/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping batch 12 as it is already completed.\n",
      "Skipping batch 8 as it is already completed.\n",
      "Skipping batch 5 as it is already completed.\n",
      "Skipping batch 4 as it is already completed.\n",
      "Skipping batch 9 as it is already completed.\n",
      "Skipping batch 16 as it is already completed.\n",
      "Skipping batch 11 as it is already completed.\n",
      "Skipping batch 7 as it is already completed.\n",
      "Skipping batch 3 as it is already completed.\n",
      "Skipping batch 18 as it is already completed.\n",
      "Skipping batch 6 as it is already completed.\n",
      "Skipping batch 13 as it is already completed.\n",
      "Skipping batch 15 as it is already completed.\n",
      "Skipping batch 14 as it is already completed.\n",
      "Skipping batch 2 as it is already completed.\n",
      "Skipping batch 17 as it is already completed.\n",
      "Skipping batch 1 as it is already completed.\n",
      "Skipping batch 10 as it is already completed.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to start an interactive session to identify best generated text in each batch.\n",
    "# This will walk through the batches randomly and present one batch at a time. \n",
    "# A batch is defined as the N texts generated from one model configuration for one prompt.\n",
    "# For each batch shown, select the best text. The method creates a new file with the final result.\n",
    "# Set ignore_completed to True if continuing from a previous session.\n",
    "# save_each_step=True ensures that the dataframe is saved after each batch is marked.\n",
    "mark_best(ignore_completed=False, save_each_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0XNT9FzpKUJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1481
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681144110131,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "f0XNT9FzpKUJ",
    "outputId": "a8587a76-8702-42eb-e69d-3561e745c97e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7be81d02-396b-4b33-a6e5-a8753a4f810c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>tuned</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prompt</th>\n",
       "      <th>score</th>\n",
       "      <th>generated</th>\n",
       "      <th>model_top_score</th>\n",
       "      <th>human_top_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>\"Are you going to do that?\" asked Lavinia.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>\"It is a pity that it is so old,\" she said.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>The old woman sat down and waited.</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>\"You are so kind, sir,\" she cried.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>\"I'm afraid of her!\" she whispered.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>18</td>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>Continue the next sentence of the story making...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>18</td>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>Continue the next sentence of the story making...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>18</td>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>Continue the next sentence of the story making...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>18</td>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>Continue the next sentence of the story making...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>18</td>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>Continue the next sentence of the story making...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 10 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7be81d02-396b-4b33-a6e5-a8753a4f810c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7be81d02-396b-4b33-a6e5-a8753a4f810c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7be81d02-396b-4b33-a6e5-a8753a4f810c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    batch_id      name                             model  tuned dataset  \\\n",
       "0          1     t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "1          1     t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "2          1     t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "3          1     t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "4          1     t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "..       ...       ...                               ...    ...     ...   \n",
       "85        18  baseline                 facebook/opt-350m  False     NaN   \n",
       "86        18  baseline                 facebook/opt-350m  False     NaN   \n",
       "87        18  baseline                 facebook/opt-350m  False     NaN   \n",
       "88        18  baseline                 facebook/opt-350m  False     NaN   \n",
       "89        18  baseline                 facebook/opt-350m  False     NaN   \n",
       "\n",
       "                                               prompt     score  \\\n",
       "0                      Lara felt very sad and scared.  0.000038   \n",
       "1                      Lara felt very sad and scared.  0.000031   \n",
       "2                      Lara felt very sad and scared.  0.000079   \n",
       "3                      Lara felt very sad and scared.  0.000033   \n",
       "4                      Lara felt very sad and scared.  0.000035   \n",
       "..                                                ...       ...   \n",
       "85  All the dragons of the world lived on one moun...  0.006471   \n",
       "86  All the dragons of the world lived on one moun...  0.002831   \n",
       "87  All the dragons of the world lived on one moun...  0.004651   \n",
       "88  All the dragons of the world lived on one moun...  0.006506   \n",
       "89  All the dragons of the world lived on one moun...  0.004662   \n",
       "\n",
       "                                            generated  model_top_score  \\\n",
       "0          \"Are you going to do that?\" asked Lavinia.            False   \n",
       "1         \"It is a pity that it is so old,\" she said.            False   \n",
       "2                  The old woman sat down and waited.             True   \n",
       "3                  \"You are so kind, sir,\" she cried.            False   \n",
       "4                 \"I'm afraid of her!\" she whispered.            False   \n",
       "..                                                ...              ...   \n",
       "85  Continue the next sentence of the story making...            False   \n",
       "86  Continue the next sentence of the story making...            False   \n",
       "87  Continue the next sentence of the story making...            False   \n",
       "88  Continue the next sentence of the story making...             True   \n",
       "89  Continue the next sentence of the story making...            False   \n",
       "\n",
       "    human_top_score  \n",
       "0              True  \n",
       "1             False  \n",
       "2             False  \n",
       "3             False  \n",
       "4             False  \n",
       "..              ...  \n",
       "85             True  \n",
       "86            False  \n",
       "87            False  \n",
       "88            False  \n",
       "89            False  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the final results with best of batch marked.\n",
    "df_results = pd.read_csv(common.annotation_with_best_loc(GDRIVE_BASE))\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9VdP1mqn1gVg",
   "metadata": {
    "id": "9VdP1mqn1gVg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1qH9or9UvtJOb_mlSSHcRjZKwZT9uDwbl",
     "timestamp": 1680142704332
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

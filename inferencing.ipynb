{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wHUaO6-oCKak",
   "metadata": {
    "id": "wHUaO6-oCKak"
   },
   "source": [
    "# T5 Tuned - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97nY_nL9CeiJ",
   "metadata": {
    "id": "97nY_nL9CeiJ"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "egOvt-Oq0M2J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17887,
     "status": "ok",
     "timestamp": 1681015649502,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "egOvt-Oq0M2J",
    "outputId": "799e4940-2f22-4326-c076-789643a383eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "GDRIVE_BASE = 'drive/MyDrive/MIDS/w266/project/'\n",
    "\n",
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RtUED7nKSww0",
   "metadata": {
    "id": "RtUED7nKSww0"
   },
   "source": [
    "## Connect to Google Drive\n",
    "We will be loading data from google drive and also save trained models to google drive. So lets mount google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "DvSvLEFgSxWH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21092,
     "status": "ok",
     "timestamp": 1681015676063,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "DvSvLEFgSxWH",
    "outputId": "61030a3e-c075-4fc8-b7fb-5744557d2029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "sys.path.insert(0, GDRIVE_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5QyOXIFTC1kO",
   "metadata": {
    "id": "5QyOXIFTC1kO"
   },
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "iyD4NJOTDDlt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 788,
     "status": "ok",
     "timestamp": 1681018074765,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "iyD4NJOTDDlt",
    "outputId": "c6ab32c6-37a9-4a86-8691-20cda477d377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "common.__version__: 1.4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer, OPTForCausalLM\n",
    "import torch\n",
    "import transformers\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm\n",
    "import common\n",
    "\n",
    "print(f'common.__version__: {common.__version__}')\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "tuning_configs = common.create_configs(GDRIVE_BASE, None, None, None, None)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UBU7IM3uc14g",
   "metadata": {
    "id": "UBU7IM3uc14g"
   },
   "source": [
    "# Story Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2r-E3q4xCa4z",
   "metadata": {
    "id": "2r-E3q4xCa4z"
   },
   "outputs": [],
   "source": [
    "class StoryBot:\n",
    "  \"\"\"Class to mimic a bot that continues the story.\"\"\"\n",
    "  def __init__(self, inferencer, n_iters=20, lines_to_use=1):\n",
    "    \"\"\"\n",
    "      Creates the interactive story bot.\n",
    "      inferencer - class to use for generating lines of the story.\n",
    "      n_iters - number of iterations to do for story generation.\n",
    "      lines_to_use - The number of lines from the story to use as context for \n",
    "                     generating the next line.\n",
    "    \"\"\"\n",
    "    self._n_iters = n_iters\n",
    "    self.lines_to_use = lines_to_use\n",
    "    self.inferencer = inferencer\n",
    "    self.re_init()\n",
    "\n",
    "  def re_init(self):\n",
    "    self.story = []\n",
    "    # Initialize queue to hold just the last \"lines_to_use\" lines of story.\n",
    "    self.context_lines = deque([], self.lines_to_use)\n",
    "\n",
    "  def display_line_choices(self, output_lines):\n",
    "    print('Choose the line of your choice:')\n",
    "    for i, line in enumerate(output_lines):\n",
    "      print(f'{i}:', line)\n",
    "    print(f'{i+1}: Regenerate')\n",
    "    print(f'{i+2}: End')\n",
    "\n",
    "  def get_user_choice(self):\n",
    "    output_lines = self.inferencer(self.context_lines)\n",
    "    if len(output_lines) > 1:\n",
    "      self.display_line_choices(output_lines)\n",
    "      user_opt = -1\n",
    "      while user_opt == -1:\n",
    "        try:\n",
    "            user_input = input('Input the number of your choice (or ): ')\n",
    "            user_opt = int(user_input)\n",
    "            if user_opt < len(output_lines):\n",
    "              return output_lines[user_opt]\n",
    "            elif user_opt == len(output_lines):\n",
    "              return 'regenerate'\n",
    "            elif user_opt == len(output_lines) + 1:\n",
    "              return 'end'\n",
    "        except ValueError:\n",
    "            user_opt = -1\n",
    "    else:\n",
    "      return output_lines[0]\n",
    "\n",
    "  def print_story(self):\n",
    "    for i, line in enumerate(self.story):\n",
    "      if i%2 == 0:\n",
    "        print(f'User: {line}') \n",
    "      else:\n",
    "        print(f'Generated: {line}') \n",
    "\n",
    "  def __call__(self):\n",
    "    print('*'*50)\n",
    "    print('Welcome to StoryBot!\\n')\n",
    "    print('This program simulates an MMS kind of interaction with a bot to create a story sequentially.')\n",
    "    print('When the prompt appears below, start typing as if it were the input on your mobile.')\n",
    "    print('Enter end to end the story and restart to restart.') \n",
    "    print('*'*50, '\\n')\n",
    "    restart = False\n",
    "    i = 0\n",
    "    while i < self._n_iters:\n",
    "      if i > 0:\n",
    "        print('The story so far:')\n",
    "        self.print_story()\n",
    "      i = i + 1\n",
    "      # get the sentence from the user\n",
    "      sentence_in = input('Enter next line (or end): ').strip()\n",
    "      # accomodate special prompts\n",
    "      if sentence_in == 'end':\n",
    "        break\n",
    "      if sentence_in == 'restart':\n",
    "        i = 0\n",
    "        self.re_init()\n",
    "        continue\n",
    "      self.context_lines.append(sentence_in)\n",
    "      self.story.append(sentence_in)\n",
    "      output = 'regenerate'\n",
    "      while output == 'regenerate':\n",
    "        output = self.get_user_choice()\n",
    "      if output == 'end':\n",
    "        break\n",
    "      self.context_lines.append(output)\n",
    "      self.story.append(output)\n",
    "\n",
    "    print()\n",
    "    print('\\n======== Final story: =========\\n')\n",
    "    self.print_story()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2NZCLlzNxAII",
   "metadata": {
    "id": "2NZCLlzNxAII"
   },
   "outputs": [],
   "source": [
    "def run_story_bot(config, device):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "  if config.model_family == 't5':\n",
    "    model = T5ForConditionalGeneration.from_pretrained(config.tuned_model_path).to(device)\n",
    "    inferencer = common.T5Inferencer(device, model, tokenizer, prompt=config.prompt)\n",
    "  else:\n",
    "    model = OPTForCausalLM.from_pretrained(config.model_name).to(device)\n",
    "    inferencer = common.OptInferencer(device, model, tokenizer)\n",
    "  story_bot = StoryBot(inferencer, n_iters=1, lines_to_use=1)\n",
    "  story_bot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BOPjAniJPRPW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36348,
     "status": "ok",
     "timestamp": 1681000226550,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "BOPjAniJPRPW",
    "outputId": "e2a3bcc9-8820-4d50-b4c3-aa8783131cea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Welcome to StoryBot!\n",
      "\n",
      "This program simulates an MMS kind of interaction with a bot to create a story sequentially.\n",
      "When the prompt appears below, start typing as if it were the input on your mobile.\n",
      "Enter end to end the story and restart to restart.\n",
      "************************************************** \n",
      "\n",
      "Enter next line (or end): The little girl felt very lonely and scared.\n",
      "Choose the line of your choice:\n",
      "0: \"It's a good thing,\" said she.\n",
      "1: \"It's a very pleasant place,\" said the little girl.\n",
      "2: \"It's all right,\" she said.\n",
      "3: Regenerate\n",
      "4: End\n",
      "Input the number of your choice (or ): 2\n",
      "\n",
      "\n",
      "======== Final story: =========\n",
      "\n",
      "User: The little girl felt very lonely and scared.\n",
      "Generated: \"It's all right,\" she said.\n"
     ]
    }
   ],
   "source": [
    "# Run story bot on t5 s1\n",
    "run_story_bot(tuning_configs['t5_s1'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iJvegk-rK13d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28706,
     "status": "ok",
     "timestamp": 1681000342592,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "iJvegk-rK13d",
    "outputId": "ec8b13f3-6ec6-48a1-ebc3-3b925111c2e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Welcome to StoryBot!\n",
      "\n",
      "This program simulates an MMS kind of interaction with a bot to create a story sequentially.\n",
      "When the prompt appears below, start typing as if it were the input on your mobile.\n",
      "Enter end to end the story and restart to restart.\n",
      "************************************************** \n",
      "\n",
      "Enter next line (or end): The little girl felt very lonely and scared.\n",
      "Choose the line of your choice:\n",
      "0: The little girl felt very lonely and scared. She was crying and crying, and her parents were crying with her, but she didn't want to talk to them because she couldn't say anything, so she just sat there and cried for a\n",
      "1: The little girl felt very lonely and scared. She wanted to go to school, but she didn't know where to find a teacher to help her. The teacher told her that she had to get a diploma to be accepted into a school.\n",
      "2: The little girl felt very lonely and scared.  She was called to the hospital to be checked out, but she was not feeling well. She was scared and didn't know what to do next. After that, she went home and slept\n",
      "3: Regenerate\n",
      "4: End\n",
      "Input the number of your choice (or ): 2\n",
      "\n",
      "\n",
      "======== Final story: =========\n",
      "\n",
      "User: The little girl felt very lonely and scared.\n",
      "Generated: The little girl felt very lonely and scared.  She was called to the hospital to be checked out, but she was not feeling well. She was scared and didn't know what to do next. After that, she went home and slept\n"
     ]
    }
   ],
   "source": [
    "# Run story bot on opt s2\n",
    "run_story_bot(tuning_configs['opt_s2'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6TUt1hxpKvDW",
   "metadata": {
    "id": "6TUt1hxpKvDW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "RIepPh55dtNF",
   "metadata": {
    "id": "RIepPh55dtNF"
   },
   "source": [
    "# Batch Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "B3-6aY66dvO_",
   "metadata": {
    "executionInfo": {
     "elapsed": 373,
     "status": "ok",
     "timestamp": 1681017853077,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "B3-6aY66dvO_"
   },
   "outputs": [],
   "source": [
    "def generate_next_line(config, line, device, num_sequences=5):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "  test_inputs = tokenizer([config.prompt + line], return_tensors='pt')\n",
    "  input_ids = test_inputs['input_ids'].to(device)\n",
    "  if config.model_family == 't5':\n",
    "    model = T5ForConditionalGeneration.from_pretrained(config.tuned_model_path).to(device)\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        num_beams=num_sequences,\n",
    "        no_repeat_ngram_size=3,\n",
    "        num_return_sequences=num_sequences,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        top_k=0,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        renormalize_logits=True,\n",
    "        # normalize_logits=True,\n",
    "      )\n",
    "  else:\n",
    "    model = OPTForCausalLM.from_pretrained(config.model_name).to(device)  \n",
    "    outputs = model.generate(\n",
    "      input_ids,\n",
    "      num_beams=num_sequences,\n",
    "      no_repeat_ngram_size=2,\n",
    "      num_return_sequences=num_sequences,\n",
    "      max_length = 50,\n",
    "      do_sample=True,\n",
    "      top_k=0,\n",
    "      early_stopping=True,\n",
    "      return_dict_in_generate=True,\n",
    "      output_scores=True,\n",
    "      renormalize_logits=True\n",
    "    )\n",
    "\n",
    "  scores = (-1 * outputs.sequences_scores).tolist()\n",
    "  test_output_ids = outputs.sequences\n",
    "  decoded = [tokenizer.decode(out_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).replace('\\n', ' ') for out_ids in test_output_ids]\n",
    "  # print(f'Input: {line}')\n",
    "  # for (score, output) in zip(scores, decoded):\n",
    "  #   print(f'\\t{score}: {output}')\n",
    "  result = [[config.model_name, config.dataset, line, score, output] for score, output in zip(scores, decoded)]\n",
    "  return result\n",
    "\n",
    "def generate_for(config, device, first_lines):\n",
    "  print('*' *50)\n",
    "  print(f'Evaluating {config.model_name} tuned on {config.dataset} dataset')\n",
    "  return generate_next_line(config, first_lines, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "z6pXWfANgeE3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c94c793b17cf4bbca623f91582498a4e",
      "5cf33eced01f4bd4b6a1d3597d1db33f",
      "af54448a131b439dbf4a5addee256489",
      "729f98146b0b449d958a810517278880",
      "2ebfa60cf36e43478f850c1de6b99e5c",
      "c955782de2934debae8062817fb6bc68",
      "83856d183c264f488d3b908dab499765",
      "b1611a376d074e7f82b5e7f792529f67",
      "786aa520d40a4be194382bf427c17800",
      "ade990bf901c4097910fd84f141f2994",
      "722cb23f0c464969b1be1db236a92131",
      "ce23fed19a254771acb5bcc9ffd41ad3",
      "54d8cb1f50184c8390c7867c05716ecb",
      "4365982107de48ac9163132a8ffbcc9d",
      "2cd06fa4b3464c878ea5c350be344b29",
      "e38f6b5c1baa4614b45047a048fb5928",
      "e303fbc2a4c34747a5d5698990dfd1ed",
      "dcb720ab1bfc4e029b4da0d7c21f9281",
      "63efb04f372d447a87cc7e94577e3800",
      "233dd2a9aeca48bbaa0af04951eaa14f",
      "42ddd446fe564c5bbd900061b8bbfafb",
      "731f870a2a3c4066961ecaaf33e423c1",
      "ad22b980e5654493888df83148581bdf",
      "176ec7d1e660400d93723478295253db",
      "1acf0596af25402cb36b21486fa77652",
      "19fce979246b4d2b9641d2aa9bf3c1e0",
      "726d35c7e5404c6484660b2faf22533c",
      "9219b915703b4f3da337f2ae29c2eb63",
      "fbb40161765a42d7a93ba38f3563f65a",
      "a0329c206ff045139a6ee5a46e35a3c0",
      "2efe590205494b62a8c30c01697ec2f0",
      "890719a9b6bd4611a93f8fda2bf1c84b",
      "5efbf8a3a60641b2bda173e026a1df8c"
     ]
    },
    "executionInfo": {
     "elapsed": 80656,
     "status": "ok",
     "timestamp": 1681018696119,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "z6pXWfANgeE3",
    "outputId": "45af3ace-aba3-4918-d07a-06421e674072"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94c793b17cf4bbca623f91582498a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prompt:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce23fed19a254771acb5bcc9ffd41ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Config:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad22b980e5654493888df83148581bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Config:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-282e6086-e623-4272-863d-e51980ac2205\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prompt</th>\n",
       "      <th>score</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>“We’ve got to go back,” she said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>“Then you must leave me alone,” said he, “and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>\"I am just going to put something into your mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>\"We are going,\" she said; \"but we are going to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>\"As if it were you who had told me the truth,\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s2</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>she began to cry, but she could not help feeli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s2</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>When the door opened she saw a beautiful white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s2</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>She had seen her father's face, and she knew t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s2</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>Then she turned round and went to her father's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s2</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>she sat down to eat and said, “There are no fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s3</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>She sat down and waited, but she soon found th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s3</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>She had never been in a place that was so beau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s3</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>Then she went to the door and asked for someth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s3</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>She had no courage, and she was very afraid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s3</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>She sat down and looked at the old woman.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s2</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>Lara felt very sad and scared. It was a very c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s2</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>Lara felt very sad and scared. She didn’t know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s2</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>Lara felt very sad and scared. She had to leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s2</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.015386</td>\n",
       "      <td>Lara felt very sad and scared. She was a young...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s2</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>Lara felt very sad and scared. Her mother told...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s3</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.013243</td>\n",
       "      <td>Lara felt very sad and scared. She had been tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s3</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.014007</td>\n",
       "      <td>Lara felt very sad and scared.  When she saw t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s3</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>Lara felt very sad and scared. When she was a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s3</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.009692</td>\n",
       "      <td>Lara felt very sad and scared. I knew she was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s3</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>Lara felt very sad and scared. \"I'm sorry, dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s1</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>He was still standing on the top of the mounta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s1</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>It was a mountain, full of dragons and dragons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s1</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>The dragons knew that the lions were swarming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s1</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>The dragon had been a long time waiting for hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s1</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>When the King came, the dragon said to him, \"I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s2</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>The dragon mountain was just like that other m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s2</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>But, when they came to the mountain, the drago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s2</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>They went to it and dwelt in it for many years.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s2</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>The dragon mountain had a green tree on its to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s2</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>There were the dragons who lived there; they l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s3</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>And the dragon mountain was the only mountain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s3</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>They were so large that it covered the whole o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s3</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>The dragons lived there in great numbers, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s3</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>They climbed up it, and they had to climb it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>google/t5-v1_1-base</td>\n",
       "      <td>s3</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>Its peaks were so high that they soared high i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s2</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.036098</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s2</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s2</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s2</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.036811</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s2</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s3</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s3</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.016841</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s3</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s3</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.035796</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>s3</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-282e6086-e623-4272-863d-e51980ac2205')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-282e6086-e623-4272-863d-e51980ac2205 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-282e6086-e623-4272-863d-e51980ac2205');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                  model dataset  \\\n",
       "0   google/t5-v1_1-base      s1   \n",
       "1   google/t5-v1_1-base      s1   \n",
       "2   google/t5-v1_1-base      s1   \n",
       "3   google/t5-v1_1-base      s1   \n",
       "4   google/t5-v1_1-base      s1   \n",
       "5   google/t5-v1_1-base      s2   \n",
       "6   google/t5-v1_1-base      s2   \n",
       "7   google/t5-v1_1-base      s2   \n",
       "8   google/t5-v1_1-base      s2   \n",
       "9   google/t5-v1_1-base      s2   \n",
       "10  google/t5-v1_1-base      s3   \n",
       "11  google/t5-v1_1-base      s3   \n",
       "12  google/t5-v1_1-base      s3   \n",
       "13  google/t5-v1_1-base      s3   \n",
       "14  google/t5-v1_1-base      s3   \n",
       "15    facebook/opt-350m      s2   \n",
       "16    facebook/opt-350m      s2   \n",
       "17    facebook/opt-350m      s2   \n",
       "18    facebook/opt-350m      s2   \n",
       "19    facebook/opt-350m      s2   \n",
       "20    facebook/opt-350m      s3   \n",
       "21    facebook/opt-350m      s3   \n",
       "22    facebook/opt-350m      s3   \n",
       "23    facebook/opt-350m      s3   \n",
       "24    facebook/opt-350m      s3   \n",
       "25  google/t5-v1_1-base      s1   \n",
       "26  google/t5-v1_1-base      s1   \n",
       "27  google/t5-v1_1-base      s1   \n",
       "28  google/t5-v1_1-base      s1   \n",
       "29  google/t5-v1_1-base      s1   \n",
       "30  google/t5-v1_1-base      s2   \n",
       "31  google/t5-v1_1-base      s2   \n",
       "32  google/t5-v1_1-base      s2   \n",
       "33  google/t5-v1_1-base      s2   \n",
       "34  google/t5-v1_1-base      s2   \n",
       "35  google/t5-v1_1-base      s3   \n",
       "36  google/t5-v1_1-base      s3   \n",
       "37  google/t5-v1_1-base      s3   \n",
       "38  google/t5-v1_1-base      s3   \n",
       "39  google/t5-v1_1-base      s3   \n",
       "40    facebook/opt-350m      s2   \n",
       "41    facebook/opt-350m      s2   \n",
       "42    facebook/opt-350m      s2   \n",
       "43    facebook/opt-350m      s2   \n",
       "44    facebook/opt-350m      s2   \n",
       "45    facebook/opt-350m      s3   \n",
       "46    facebook/opt-350m      s3   \n",
       "47    facebook/opt-350m      s3   \n",
       "48    facebook/opt-350m      s3   \n",
       "49    facebook/opt-350m      s3   \n",
       "\n",
       "                                               prompt     score  \\\n",
       "0                      Lara felt very sad and scared.  0.000033   \n",
       "1                      Lara felt very sad and scared.  0.000028   \n",
       "2                      Lara felt very sad and scared.  0.000023   \n",
       "3                      Lara felt very sad and scared.  0.000041   \n",
       "4                      Lara felt very sad and scared.  0.000027   \n",
       "5                      Lara felt very sad and scared.  0.000040   \n",
       "6                      Lara felt very sad and scared.  0.000032   \n",
       "7                      Lara felt very sad and scared.  0.000036   \n",
       "8                      Lara felt very sad and scared.  0.000069   \n",
       "9                      Lara felt very sad and scared.  0.000029   \n",
       "10                     Lara felt very sad and scared.  0.000025   \n",
       "11                     Lara felt very sad and scared.  0.000028   \n",
       "12                     Lara felt very sad and scared.  0.000035   \n",
       "13                     Lara felt very sad and scared.  0.000049   \n",
       "14                     Lara felt very sad and scared.  0.000031   \n",
       "15                     Lara felt very sad and scared.  0.021338   \n",
       "16                     Lara felt very sad and scared.  0.012462   \n",
       "17                     Lara felt very sad and scared.  0.001985   \n",
       "18                     Lara felt very sad and scared.  0.015386   \n",
       "19                     Lara felt very sad and scared.  0.012401   \n",
       "20                     Lara felt very sad and scared.  0.013243   \n",
       "21                     Lara felt very sad and scared.  0.014007   \n",
       "22                     Lara felt very sad and scared.  0.004358   \n",
       "23                     Lara felt very sad and scared.  0.009692   \n",
       "24                     Lara felt very sad and scared.  0.000008   \n",
       "25  All the dragons of the world lived on one moun...  0.000085   \n",
       "26  All the dragons of the world lived on one moun...  0.000084   \n",
       "27  All the dragons of the world lived on one moun...  0.000065   \n",
       "28  All the dragons of the world lived on one moun...  0.000049   \n",
       "29  All the dragons of the world lived on one moun...  0.000034   \n",
       "30  All the dragons of the world lived on one moun...  0.000161   \n",
       "31  All the dragons of the world lived on one moun...  0.000036   \n",
       "32  All the dragons of the world lived on one moun...  0.000315   \n",
       "33  All the dragons of the world lived on one moun...  0.000106   \n",
       "34  All the dragons of the world lived on one moun...  0.000137   \n",
       "35  All the dragons of the world lived on one moun...  0.000050   \n",
       "36  All the dragons of the world lived on one moun...  0.000240   \n",
       "37  All the dragons of the world lived on one moun...  0.000290   \n",
       "38  All the dragons of the world lived on one moun...  0.000265   \n",
       "39  All the dragons of the world lived on one moun...  0.000210   \n",
       "40  All the dragons of the world lived on one moun...  0.036098   \n",
       "41  All the dragons of the world lived on one moun...  0.009466   \n",
       "42  All the dragons of the world lived on one moun...  0.007124   \n",
       "43  All the dragons of the world lived on one moun...  0.036811   \n",
       "44  All the dragons of the world lived on one moun...  0.014037   \n",
       "45  All the dragons of the world lived on one moun...  0.010583   \n",
       "46  All the dragons of the world lived on one moun...  0.016841   \n",
       "47  All the dragons of the world lived on one moun...  0.011761   \n",
       "48  All the dragons of the world lived on one moun...  0.035796   \n",
       "49  All the dragons of the world lived on one moun...  0.001766   \n",
       "\n",
       "                                            generated  \n",
       "0                   “We’ve got to go back,” she said.  \n",
       "1   “Then you must leave me alone,” said he, “and ...  \n",
       "2   \"I am just going to put something into your mo...  \n",
       "3   \"We are going,\" she said; \"but we are going to...  \n",
       "4   \"As if it were you who had told me the truth,\"...  \n",
       "5   she began to cry, but she could not help feeli...  \n",
       "6   When the door opened she saw a beautiful white...  \n",
       "7   She had seen her father's face, and she knew t...  \n",
       "8   Then she turned round and went to her father's...  \n",
       "9   she sat down to eat and said, “There are no fo...  \n",
       "10  She sat down and waited, but she soon found th...  \n",
       "11  She had never been in a place that was so beau...  \n",
       "12  Then she went to the door and asked for someth...  \n",
       "13       She had no courage, and she was very afraid.  \n",
       "14          She sat down and looked at the old woman.  \n",
       "15  Lara felt very sad and scared. It was a very c...  \n",
       "16  Lara felt very sad and scared. She didn’t know...  \n",
       "17  Lara felt very sad and scared. She had to leav...  \n",
       "18  Lara felt very sad and scared. She was a young...  \n",
       "19  Lara felt very sad and scared. Her mother told...  \n",
       "20  Lara felt very sad and scared. She had been tr...  \n",
       "21  Lara felt very sad and scared.  When she saw t...  \n",
       "22  Lara felt very sad and scared. When she was a ...  \n",
       "23  Lara felt very sad and scared. I knew she was ...  \n",
       "24  Lara felt very sad and scared. \"I'm sorry, dea...  \n",
       "25  He was still standing on the top of the mounta...  \n",
       "26  It was a mountain, full of dragons and dragons...  \n",
       "27  The dragons knew that the lions were swarming ...  \n",
       "28  The dragon had been a long time waiting for hi...  \n",
       "29  When the King came, the dragon said to him, \"I...  \n",
       "30  The dragon mountain was just like that other m...  \n",
       "31  But, when they came to the mountain, the drago...  \n",
       "32    They went to it and dwelt in it for many years.  \n",
       "33  The dragon mountain had a green tree on its to...  \n",
       "34  There were the dragons who lived there; they l...  \n",
       "35  And the dragon mountain was the only mountain ...  \n",
       "36  They were so large that it covered the whole o...  \n",
       "37  The dragons lived there in great numbers, and ...  \n",
       "38  They climbed up it, and they had to climb it, ...  \n",
       "39  Its peaks were so high that they soared high i...  \n",
       "40  All the dragons of the world lived on one moun...  \n",
       "41  All the dragons of the world lived on one moun...  \n",
       "42  All the dragons of the world lived on one moun...  \n",
       "43  All the dragons of the world lived on one moun...  \n",
       "44  All the dragons of the world lived on one moun...  \n",
       "45  All the dragons of the world lived on one moun...  \n",
       "46  All the dragons of the world lived on one moun...  \n",
       "47  All the dragons of the world lived on one moun...  \n",
       "48  All the dragons of the world lived on one moun...  \n",
       "49  All the dragons of the world lived on one moun...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_lines = ['Lara felt very sad and scared.', 'All the dragons of the world lived on one mountain called the dragon mountain.']\n",
    "results = []\n",
    "\n",
    "for line in tqdm(first_lines, desc='Prompts'):\n",
    "  for name, config in tqdm(tuning_configs.items(), desc='Models' leave=False):\n",
    "    results.extend(generate_next_line(config, line, device))\n",
    "df_results = pd.DataFrame(results, columns=['model', 'dataset', 'prompt', 'score', 'generated'])\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pTF_5WE-d7rv",
   "metadata": {
    "id": "pTF_5WE-d7rv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UBU7IM3uc14g"
   ],
   "provenance": [
    {
     "file_id": "1qH9or9UvtJOb_mlSSHcRjZKwZT9uDwbl",
     "timestamp": 1680142704332
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

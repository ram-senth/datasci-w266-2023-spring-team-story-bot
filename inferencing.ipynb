{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wHUaO6-oCKak",
   "metadata": {
    "id": "wHUaO6-oCKak"
   },
   "source": [
    "# Tuned - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97nY_nL9CeiJ",
   "metadata": {
    "id": "97nY_nL9CeiJ"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "egOvt-Oq0M2J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19289,
     "status": "ok",
     "timestamp": 1681094176753,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "egOvt-Oq0M2J",
    "outputId": "64f43d59-4699-4ec7-9467-c5155fdba94a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "GDRIVE_BASE = 'drive/MyDrive/MIDS/w266/project/'\n",
    "\n",
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RtUED7nKSww0",
   "metadata": {
    "id": "RtUED7nKSww0"
   },
   "source": [
    "## Connect to Google Drive\n",
    "We will be loading data from google drive and also save trained models to google drive. So lets mount google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "DvSvLEFgSxWH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37068,
     "status": "ok",
     "timestamp": 1681094219415,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "DvSvLEFgSxWH",
    "outputId": "559dc4a9-adc6-43f3-e1b2-7fe56059c4f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "sys.path.insert(0, GDRIVE_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5QyOXIFTC1kO",
   "metadata": {
    "id": "5QyOXIFTC1kO"
   },
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "iyD4NJOTDDlt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1681098785975,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "iyD4NJOTDDlt",
    "outputId": "674fa7c4-9fa7-470a-de23-8ec4e6423b82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "common.__version__: 1.4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer, OPTForCausalLM\n",
    "from transformers import BertTokenizerFast, BertTokenizer, BertConfig\n",
    "from transformers import EncoderDecoderModel, EncoderDecoderConfig\n",
    "import torch\n",
    "import transformers\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm\n",
    "import common\n",
    "\n",
    "print(f'common.__version__: {common.__version__}')\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "tuning_configs = common.create_configs(GDRIVE_BASE)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "QWGaFrKPNIPz",
   "metadata": {
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1681098243415,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "QWGaFrKPNIPz"
   },
   "outputs": [],
   "source": [
    "def tokenizer_for(config):\n",
    "  if config.model_family == 'bert':\n",
    "    return BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
    "  else:\n",
    "    return AutoTokenizer.from_pretrained(config.base_model)\n",
    "\n",
    "def model_for(config):\n",
    "  if config.model_family == 't5':\n",
    "    if config.tuned:\n",
    "      return T5ForConditionalGeneration.from_pretrained(config.tuned_model_path).to(device)\n",
    "    else:\n",
    "      return T5ForConditionalGeneration.from_pretrained(config.model_name).to(device)\n",
    "\n",
    "  if config.model_family == 'opt':\n",
    "    if config.tuned:\n",
    "      return OPTForCausalLM.from_pretrained(config.tuned_model_path).to(device)\n",
    "    else:\n",
    "      return OPTForCausalLM.from_pretrained(config.model_name).to(device)  \n",
    "\n",
    "  return EncoderDecoderModel.from_pretrained(config.tuned_model_path).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UBU7IM3uc14g",
   "metadata": {
    "id": "UBU7IM3uc14g"
   },
   "source": [
    "# Story Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2r-E3q4xCa4z",
   "metadata": {
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1681098792011,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "2r-E3q4xCa4z"
   },
   "outputs": [],
   "source": [
    "class StoryBot:\n",
    "  \"\"\"Class to mimic a bot that continues the story.\"\"\"\n",
    "  def __init__(self, inferencer, n_iters=20, lines_to_use=1):\n",
    "    \"\"\"\n",
    "      Creates the interactive story bot.\n",
    "      inferencer - class to use for generating lines of the story.\n",
    "      n_iters - number of iterations to do for story generation.\n",
    "      lines_to_use - The number of lines from the story to use as context for \n",
    "                     generating the next line.\n",
    "    \"\"\"\n",
    "    self._n_iters = n_iters\n",
    "    self.lines_to_use = lines_to_use\n",
    "    self.inferencer = inferencer\n",
    "    self.re_init()\n",
    "\n",
    "  def re_init(self):\n",
    "    self.story = []\n",
    "    # Initialize queue to hold just the last \"lines_to_use\" lines of story.\n",
    "    self.context_lines = deque([], self.lines_to_use)\n",
    "\n",
    "  def display_line_choices(self, output_lines):\n",
    "    print('Choose the line of your choice:')\n",
    "    for i, line in enumerate(output_lines):\n",
    "      print(f'{i}:', line)\n",
    "    print(f'{i+1}: Regenerate')\n",
    "    print(f'{i+2}: End')\n",
    "\n",
    "  def get_user_choice(self):\n",
    "    output_lines = self.inferencer(self.context_lines)\n",
    "    if len(output_lines) > 1:\n",
    "      self.display_line_choices(output_lines)\n",
    "      user_opt = -1\n",
    "      while user_opt == -1:\n",
    "        try:\n",
    "            user_input = input('Input the number of your choice (or ): ')\n",
    "            user_opt = int(user_input)\n",
    "            if user_opt < len(output_lines):\n",
    "              return output_lines[user_opt]\n",
    "            elif user_opt == len(output_lines):\n",
    "              return 'regenerate'\n",
    "            elif user_opt == len(output_lines) + 1:\n",
    "              return 'end'\n",
    "        except ValueError:\n",
    "            user_opt = -1\n",
    "    else:\n",
    "      return output_lines[0]\n",
    "\n",
    "  def print_story(self):\n",
    "    for i, line in enumerate(self.story):\n",
    "      if i%2 == 0:\n",
    "        print(f'User: {line}') \n",
    "      else:\n",
    "        print(f'Generated: {line}') \n",
    "\n",
    "  def __call__(self):\n",
    "    print('*'*50)\n",
    "    print('Welcome to StoryBot!\\n')\n",
    "    print('This program simulates an MMS kind of interaction with a bot to create a story sequentially.')\n",
    "    print('When the prompt appears below, start typing as if it were the input on your mobile.')\n",
    "    print('Enter end to end the story and restart to restart.') \n",
    "    print('*'*50, '\\n')\n",
    "    restart = False\n",
    "    i = 0\n",
    "    while i < self._n_iters:\n",
    "      if i > 0:\n",
    "        print('The story so far:')\n",
    "        self.print_story()\n",
    "      i = i + 1\n",
    "      # get the sentence from the user\n",
    "      sentence_in = input('Enter next line (or end): ').strip()\n",
    "      # accomodate special prompts\n",
    "      if sentence_in == 'end':\n",
    "        break\n",
    "      if sentence_in == 'restart':\n",
    "        i = 0\n",
    "        self.re_init()\n",
    "        continue\n",
    "      self.context_lines.append(sentence_in)\n",
    "      self.story.append(sentence_in)\n",
    "      output = 'regenerate'\n",
    "      while output == 'regenerate':\n",
    "        output = self.get_user_choice()\n",
    "      if output == 'end':\n",
    "        break\n",
    "      self.context_lines.append(output)\n",
    "      self.story.append(output)\n",
    "\n",
    "    print()\n",
    "    print('\\n======== Final story: =========\\n')\n",
    "    self.print_story()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2NZCLlzNxAII",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681098795114,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "2NZCLlzNxAII"
   },
   "outputs": [],
   "source": [
    "def run_story_bot(config, device):\n",
    "  tokenizer = tokenizer_for(config)\n",
    "  model = model_for(config)\n",
    "  if config.model_family == 't5':\n",
    "    inferencer = common.T5Inferencer(device, model, tokenizer, prompt=config.prompt)\n",
    "  elif config.model_family == 'opt':\n",
    "    inferencer = common.OptInferencer(device, model, tokenizer)\n",
    "  else:\n",
    "    inferencer = common.B2BInferencer(device, model, tokenizer)\n",
    "  story_bot = StoryBot(inferencer, n_iters=5, lines_to_use=1)\n",
    "  story_bot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "BOPjAniJPRPW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43642,
     "status": "ok",
     "timestamp": 1681098880916,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "BOPjAniJPRPW",
    "outputId": "7f696c6e-82ee-4268-e1c1-c5c125898614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Welcome to StoryBot!\n",
      "\n",
      "This program simulates an MMS kind of interaction with a bot to create a story sequentially.\n",
      "When the prompt appears below, start typing as if it were the input on your mobile.\n",
      "Enter end to end the story and restart to restart.\n",
      "************************************************** \n",
      "\n",
      "Enter next line (or end): He did not like what he saw.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the line of your choice:\n",
      "0: He had never seen such a thing in his life.\n",
      "1: He had never seen such a thing in his life, and he was afraid of it.\n",
      "2: He had never seen such a thing before.\n",
      "3: Regenerate\n",
      "4: End\n",
      "Input the number of your choice (or ): 1\n",
      "\n",
      "\n",
      "======== Final story: =========\n",
      "\n",
      "User: He did not like what he saw.\n",
      "Generated: He had never seen such a thing in his life, and he was afraid of it.\n"
     ]
    }
   ],
   "source": [
    "# Run story bot on t5 s1\n",
    "run_story_bot(tuning_configs['b2b_s1'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RIepPh55dtNF",
   "metadata": {
    "id": "RIepPh55dtNF"
   },
   "source": [
    "# Batch Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "B3-6aY66dvO_",
   "metadata": {
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1681098228466,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "B3-6aY66dvO_"
   },
   "outputs": [],
   "source": [
    "def max_score_index(scores):\n",
    "  max_score = scores[0]\n",
    "  max_score_index = 0\n",
    "  for i, score in enumerate(scores):\n",
    "    if score > max_score:\n",
    "      # New max score\n",
    "      max_score = score\n",
    "      max_score_index = i\n",
    "  return max_score_index\n",
    "\n",
    "def generate_next_line(config, line, device, num_sequences=5, max_new_tokens=50):\n",
    "  tokenizer = tokenizer_for(config)\n",
    "  model = model_for(config)\n",
    "  test_inputs = tokenizer([config.prompt + line], return_tensors='pt')\n",
    "  input_ids = test_inputs['input_ids'].to(device)\n",
    "  if config.model_family == 't5':\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        num_beams=num_sequences,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=num_sequences,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        top_k=0,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        renormalize_logits=True,\n",
    "      )\n",
    "  elif config.model_family == 'opt':\n",
    "    outputs = model.generate(\n",
    "      input_ids,\n",
    "      num_beams=num_sequences,\n",
    "      no_repeat_ngram_size=2,\n",
    "      num_return_sequences=num_sequences,\n",
    "      max_length = max_new_tokens,\n",
    "      do_sample=True,\n",
    "      top_k=0,\n",
    "      early_stopping=True,\n",
    "      return_dict_in_generate=True,\n",
    "      output_scores=True,\n",
    "      renormalize_logits=True\n",
    "    )\n",
    "  else:\n",
    "    outputs = model.generate(\n",
    "        input_ids, \n",
    "        # attention_mask=attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_beams=num_sequences,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=num_sequences,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        renormalize_logits=True)\n",
    "    \n",
    "  scores = (-1 * outputs.sequences_scores).tolist()\n",
    "  test_output_ids = outputs.sequences\n",
    "  decoded = [tokenizer.decode(out_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).replace('\\n', ' ') for out_ids in test_output_ids]\n",
    "\n",
    "  result = [[config.name, config.model_name, config.tuned, config.dataset, line, score, output, False] for score, output in zip(scores, decoded)]\n",
    "  result[max_score_index(scores)][-1] = True\n",
    "  return result\n",
    "\n",
    "def generate_for(config, device, first_lines):\n",
    "  print('*' *50)\n",
    "  print(f'Evaluating {config.model_name} tuned on {config.dataset} dataset')\n",
    "  return generate_next_line(config, first_lines, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "z6pXWfANgeE3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "299d583a87b242828b11c47cf6b911d8",
      "7634c652614d40049ded70ce0822863c",
      "2b18471ffde7404397292d49de659320",
      "70b86611ed374cf5b393a16493f3171b",
      "3a5cb00a3b344071938cfca2c18f713c",
      "33e7faa202e04242ae9bfb76eb9e4c07",
      "570260bab6a94f58ac3f24e6f0ffb86c",
      "f435e602fa4c44179efcc410f4570fbb",
      "3e8582dad81e4e58addad93e5d97730c",
      "1eafea5118024ae0af4f7e00696a55a9",
      "f33aeda67b20467da17642028133264a"
     ]
    },
    "executionInfo": {
     "elapsed": 185107,
     "status": "ok",
     "timestamp": 1681098435968,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "z6pXWfANgeE3",
    "outputId": "569670a1-edec-4ea7-a2b1-8b7504704f37"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299d583a87b242828b11c47cf6b911d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/18.0 [00:00<?, ?text genaration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "first_lines = ['Lara felt very sad and scared.', 'All the dragons of the world lived on one mountain called the dragon mountain.']\n",
    "results = []\n",
    "\n",
    "with tqdm(total=len(tuning_configs) * len(first_lines), unit='text genaration', unit_scale=True) as pbar:\n",
    "  for line in first_lines:\n",
    "    for name, config in tuning_configs.items():\n",
    "      pbar.set_postfix(model=name, prompt=line[0:10] + '...', refresh=True)\n",
    "      results.extend(generate_next_line(config, line, device))\n",
    "      pbar.update(1)\n",
    "  df_results = pd.DataFrame(results, columns=['name', 'model', 'tuned', 'dataset', 'prompt', 'score', 'top_scored', 'generated'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "pTF_5WE-d7rv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7252
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1681098443774,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "pTF_5WE-d7rv",
    "outputId": "d6c518b1-884a-4deb-b686-a9eed9e8c89a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1d31d889-6e31-4719-8a3d-2637811a32ad\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>tuned</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prompt</th>\n",
       "      <th>score</th>\n",
       "      <th>top_scored</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>\"What does this mean?\" he said, \"that it is no...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>When she had a good sleep, she took supper and...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>\"Ah!\" said Mrs. Dashwood.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>\"It is a very pleasant place to live in,\" he s...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>Then she cried, “Tell us what you have done, a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d31d889-6e31-4719-8a3d-2637811a32ad')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1d31d889-6e31-4719-8a3d-2637811a32ad button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1d31d889-6e31-4719-8a3d-2637811a32ad');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        name                             model  tuned dataset  \\\n",
       "0      t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "1      t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "2      t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "3      t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "4      t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "..       ...                               ...    ...     ...   \n",
       "85  baseline                 facebook/opt-350m  False    None   \n",
       "86  baseline                 facebook/opt-350m  False    None   \n",
       "87  baseline                 facebook/opt-350m  False    None   \n",
       "88  baseline                 facebook/opt-350m  False    None   \n",
       "89  baseline                 facebook/opt-350m  False    None   \n",
       "\n",
       "                                               prompt     score  \\\n",
       "0                      Lara felt very sad and scared.  0.000045   \n",
       "1                      Lara felt very sad and scared.  0.000065   \n",
       "2                      Lara felt very sad and scared.  0.000040   \n",
       "3                      Lara felt very sad and scared.  0.000034   \n",
       "4                      Lara felt very sad and scared.  0.000032   \n",
       "..                                                ...       ...   \n",
       "85  All the dragons of the world lived on one moun...  0.015118   \n",
       "86  All the dragons of the world lived on one moun...  0.036302   \n",
       "87  All the dragons of the world lived on one moun...  0.006007   \n",
       "88  All the dragons of the world lived on one moun...  0.008222   \n",
       "89  All the dragons of the world lived on one moun...  0.008341   \n",
       "\n",
       "                                           top_scored  generated  \n",
       "0   \"What does this mean?\" he said, \"that it is no...      False  \n",
       "1   When she had a good sleep, she took supper and...       True  \n",
       "2                           \"Ah!\" said Mrs. Dashwood.      False  \n",
       "3   \"It is a very pleasant place to live in,\" he s...      False  \n",
       "4   Then she cried, “Tell us what you have done, a...      False  \n",
       "..                                                ...        ...  \n",
       "85  All the dragons of the world lived on one moun...      False  \n",
       "86  All the dragons of the world lived on one moun...       True  \n",
       "87  All the dragons of the world lived on one moun...      False  \n",
       "88  All the dragons of the world lived on one moun...      False  \n",
       "89  All the dragons of the world lived on one moun...      False  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZqiupvHh7VmF",
   "metadata": {
    "id": "ZqiupvHh7VmF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1qH9or9UvtJOb_mlSSHcRjZKwZT9uDwbl",
     "timestamp": 1680142704332
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wHUaO6-oCKak",
   "metadata": {
    "id": "wHUaO6-oCKak"
   },
   "source": [
    "# Tuned - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97nY_nL9CeiJ",
   "metadata": {
    "id": "97nY_nL9CeiJ"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "egOvt-Oq0M2J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28661,
     "status": "ok",
     "timestamp": 1681139030407,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "egOvt-Oq0M2J",
    "outputId": "58f98580-ccfe-425e-a355-d78086410260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "GDRIVE_BASE = 'drive/MyDrive/MIDS/w266/project/'\n",
    "\n",
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RtUED7nKSww0",
   "metadata": {
    "id": "RtUED7nKSww0"
   },
   "source": [
    "## Connect to Google Drive\n",
    "We will be loading data from google drive and also save trained models to google drive. So lets mount google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "DvSvLEFgSxWH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68018,
     "status": "ok",
     "timestamp": 1681139098418,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "DvSvLEFgSxWH",
    "outputId": "bdf1cd12-0f34-4d3f-e9f0-0d8563892d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "sys.path.insert(0, GDRIVE_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5QyOXIFTC1kO",
   "metadata": {
    "id": "5QyOXIFTC1kO"
   },
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "iyD4NJOTDDlt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9342,
     "status": "ok",
     "timestamp": 1681139107757,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "iyD4NJOTDDlt",
    "outputId": "db202ef2-0c83-4ab9-e095-533636cbb434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common.__version__: 1.4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer, OPTForCausalLM\n",
    "from transformers import BertTokenizerFast, BertTokenizer, BertConfig\n",
    "from transformers import EncoderDecoderModel, EncoderDecoderConfig\n",
    "import torch\n",
    "import transformers\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm\n",
    "import common\n",
    "\n",
    "print(f'common.__version__: {common.__version__}')\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "tuning_configs = common.create_configs(GDRIVE_BASE)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "QWGaFrKPNIPz",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681139107758,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "QWGaFrKPNIPz"
   },
   "outputs": [],
   "source": [
    "def tokenizer_for(config):\n",
    "  if config.model_family == 'bert':\n",
    "    return BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
    "  else:\n",
    "    return AutoTokenizer.from_pretrained(config.base_model)\n",
    "\n",
    "def model_for(config):\n",
    "  if config.model_family == 't5':\n",
    "    if config.tuned:\n",
    "      return T5ForConditionalGeneration.from_pretrained(config.tuned_model_path).to(device)\n",
    "    else:\n",
    "      return T5ForConditionalGeneration.from_pretrained(config.model_name).to(device)\n",
    "\n",
    "  if config.model_family == 'opt':\n",
    "    if config.tuned:\n",
    "      return OPTForCausalLM.from_pretrained(config.tuned_model_path).to(device)\n",
    "    else:\n",
    "      return OPTForCausalLM.from_pretrained(config.model_name).to(device)  \n",
    "\n",
    "  return EncoderDecoderModel.from_pretrained(config.tuned_model_path).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UBU7IM3uc14g",
   "metadata": {
    "id": "UBU7IM3uc14g"
   },
   "source": [
    "# Story Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2r-E3q4xCa4z",
   "metadata": {
    "id": "2r-E3q4xCa4z"
   },
   "outputs": [],
   "source": [
    "class StoryBot:\n",
    "  \"\"\"Class to mimic a bot that continues the story.\"\"\"\n",
    "  def __init__(self, inferencer, n_iters=20, lines_to_use=1):\n",
    "    \"\"\"\n",
    "      Creates the interactive story bot.\n",
    "      inferencer - class to use for generating lines of the story.\n",
    "      n_iters - number of iterations to do for story generation.\n",
    "      lines_to_use - The number of lines from the story to use as context for \n",
    "                     generating the next line.\n",
    "    \"\"\"\n",
    "    self._n_iters = n_iters\n",
    "    self.lines_to_use = lines_to_use\n",
    "    self.inferencer = inferencer\n",
    "    self.re_init()\n",
    "\n",
    "  def re_init(self):\n",
    "    self.story = []\n",
    "    # Initialize queue to hold just the last \"lines_to_use\" lines of story.\n",
    "    self.context_lines = deque([], self.lines_to_use)\n",
    "\n",
    "  def display_line_choices(self, output_lines):\n",
    "    print('Choose the line of your choice:')\n",
    "    for i, line in enumerate(output_lines):\n",
    "      print(f'{i}:', line)\n",
    "    print(f'{i+1}: Regenerate')\n",
    "    print(f'{i+2}: End')\n",
    "\n",
    "  def get_user_choice(self):\n",
    "    output_lines = self.inferencer(self.context_lines)\n",
    "    if len(output_lines) > 1:\n",
    "      self.display_line_choices(output_lines)\n",
    "      user_opt = -1\n",
    "      while user_opt == -1:\n",
    "        try:\n",
    "            user_input = input('Input the number of your choice (or ): ')\n",
    "            user_opt = int(user_input)\n",
    "            if user_opt < len(output_lines):\n",
    "              return output_lines[user_opt]\n",
    "            elif user_opt == len(output_lines):\n",
    "              return 'regenerate'\n",
    "            elif user_opt == len(output_lines) + 1:\n",
    "              return 'end'\n",
    "        except ValueError:\n",
    "            user_opt = -1\n",
    "    else:\n",
    "      return output_lines[0]\n",
    "\n",
    "  def print_story(self):\n",
    "    for i, line in enumerate(self.story):\n",
    "      if i%2 == 0:\n",
    "        print(f'User: {line}') \n",
    "      else:\n",
    "        print(f'Generated: {line}') \n",
    "\n",
    "  def __call__(self):\n",
    "    print('*'*50)\n",
    "    print('Welcome to StoryBot!\\n')\n",
    "    print('This program simulates an MMS kind of interaction with a bot to create a story sequentially.')\n",
    "    print('When the prompt appears below, start typing as if it were the input on your mobile.')\n",
    "    print('Enter end to end the story and restart to restart.') \n",
    "    print('*'*50, '\\n')\n",
    "    restart = False\n",
    "    i = 0\n",
    "    while i < self._n_iters:\n",
    "      if i > 0:\n",
    "        print('The story so far:')\n",
    "        self.print_story()\n",
    "      i = i + 1\n",
    "      # get the sentence from the user\n",
    "      sentence_in = input('Enter next line (or end): ').strip()\n",
    "      # accomodate special prompts\n",
    "      if sentence_in == 'end':\n",
    "        break\n",
    "      if sentence_in == 'restart':\n",
    "        i = 0\n",
    "        self.re_init()\n",
    "        continue\n",
    "      self.context_lines.append(sentence_in)\n",
    "      self.story.append(sentence_in)\n",
    "      output = 'regenerate'\n",
    "      while output == 'regenerate':\n",
    "        output = self.get_user_choice()\n",
    "      if output == 'end':\n",
    "        break\n",
    "      self.context_lines.append(output)\n",
    "      self.story.append(output)\n",
    "\n",
    "    print()\n",
    "    print('\\n======== Final story: =========\\n')\n",
    "    self.print_story()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2NZCLlzNxAII",
   "metadata": {
    "id": "2NZCLlzNxAII"
   },
   "outputs": [],
   "source": [
    "def run_story_bot(config, device):\n",
    "  tokenizer = tokenizer_for(config)\n",
    "  model = model_for(config)\n",
    "  if config.model_family == 't5':\n",
    "    inferencer = common.T5Inferencer(device, model, tokenizer, prompt=config.prompt)\n",
    "  elif config.model_family == 'opt':\n",
    "    inferencer = common.OptInferencer(device, model, tokenizer)\n",
    "  else:\n",
    "    inferencer = common.B2BInferencer(device, model, tokenizer)\n",
    "  story_bot = StoryBot(inferencer, n_iters=5, lines_to_use=1)\n",
    "  story_bot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BOPjAniJPRPW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43642,
     "status": "ok",
     "timestamp": 1681098880916,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "BOPjAniJPRPW",
    "outputId": "7f696c6e-82ee-4268-e1c1-c5c125898614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Welcome to StoryBot!\n",
      "\n",
      "This program simulates an MMS kind of interaction with a bot to create a story sequentially.\n",
      "When the prompt appears below, start typing as if it were the input on your mobile.\n",
      "Enter end to end the story and restart to restart.\n",
      "************************************************** \n",
      "\n",
      "Enter next line (or end): He did not like what he saw.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the line of your choice:\n",
      "0: He had never seen such a thing in his life.\n",
      "1: He had never seen such a thing in his life, and he was afraid of it.\n",
      "2: He had never seen such a thing before.\n",
      "3: Regenerate\n",
      "4: End\n",
      "Input the number of your choice (or ): 1\n",
      "\n",
      "\n",
      "======== Final story: =========\n",
      "\n",
      "User: He did not like what he saw.\n",
      "Generated: He had never seen such a thing in his life, and he was afraid of it.\n"
     ]
    }
   ],
   "source": [
    "# Run story bot on t5 s1\n",
    "run_story_bot(tuning_configs['b2b_s1'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RIepPh55dtNF",
   "metadata": {
    "id": "RIepPh55dtNF"
   },
   "source": [
    "# Batch Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "B3-6aY66dvO_",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681139107758,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "B3-6aY66dvO_"
   },
   "outputs": [],
   "source": [
    "def max_score_index(scores):\n",
    "  max_score = scores[0]\n",
    "  max_score_index = 0\n",
    "  for i, score in enumerate(scores):\n",
    "    if score > max_score:\n",
    "      # New max score\n",
    "      max_score = score\n",
    "      max_score_index = i\n",
    "  return max_score_index\n",
    "\n",
    "def generate_next_line(batch_id, config, line, device, num_sequences=5, max_new_tokens=50):\n",
    "  tokenizer = tokenizer_for(config)\n",
    "  model = model_for(config)\n",
    "  test_inputs = tokenizer([config.prompt + line], return_tensors='pt')\n",
    "  input_ids = test_inputs['input_ids'].to(device)\n",
    "  if config.model_family == 't5':\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        num_beams=num_sequences,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=num_sequences,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        top_k=0,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        renormalize_logits=True,\n",
    "      )\n",
    "  elif config.model_family == 'opt':\n",
    "    outputs = model.generate(\n",
    "      input_ids,\n",
    "      num_beams=num_sequences,\n",
    "      no_repeat_ngram_size=2,\n",
    "      num_return_sequences=num_sequences,\n",
    "      max_length = max_new_tokens,\n",
    "      do_sample=True,\n",
    "      top_k=0,\n",
    "      early_stopping=True,\n",
    "      return_dict_in_generate=True,\n",
    "      output_scores=True,\n",
    "      renormalize_logits=True\n",
    "    )\n",
    "  else:\n",
    "    outputs = model.generate(\n",
    "        input_ids, \n",
    "        # attention_mask=attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_beams=num_sequences,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=num_sequences,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        renormalize_logits=True)\n",
    "    \n",
    "  scores = (-1 * outputs.sequences_scores).tolist()\n",
    "  test_output_ids = outputs.sequences\n",
    "  decoded = [tokenizer.decode(out_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).replace('\\n', ' ') for out_ids in test_output_ids]\n",
    "\n",
    "  result = [[batch_id, config.name, config.model_name, config.tuned, config.dataset, line, score, output, False] for score, output in zip(scores, decoded)]\n",
    "  result[max_score_index(scores)][-1] = True\n",
    "  return result\n",
    "\n",
    "def generate_for(first_lines, device, models=None):\n",
    "  \"\"\"\n",
    "    Generates a new line for each line in first_lines and for each model. \n",
    "    If models is not None then the generation is limited to the models specified \n",
    "    else it is generated for all models in tuning_configs.\n",
    "  \"\"\"\n",
    "  if models is None:\n",
    "    models = tuning_configs.keys()\n",
    "  with tqdm(total=len(models) * len(first_lines), unit='text generation', unit_scale=True) as pbar:\n",
    "    results = []\n",
    "    batch_id = 1\n",
    "    for line in first_lines:\n",
    "      for name in models:\n",
    "        config = tuning_configs[name]\n",
    "        pbar.set_postfix(model=name, prompt=line[0:10] + '...', refresh=True)\n",
    "        results.extend(generate_next_line(batch_id, config, line, device))\n",
    "        batch_id = batch_id + 1\n",
    "        pbar.update(1)\n",
    "    return pd.DataFrame(results, columns=['batch_id', 'name', 'model', 'tuned', 'dataset', 'prompt', 'score', 'generated', 'model_top_score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "GMR653amkfZp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620,
     "referenced_widgets": [
      "c088bf04115a4e28981721906fb0feb5",
      "8d5ec12aa8e646bba80b2c3edabca93f",
      "cbfdddfa866040e2a8bbab200e897b21",
      "b9911a94383e48348a406b8a1df5d907",
      "c8a160cfe2d64b8a9256056638aea404",
      "9f4fad2f6d2f48938757286b791342c5",
      "e9528f2840a34719b59afbb65910b031",
      "f17b64b1a1834acc95713ec15981fb25",
      "d4e7f2ee281a45edb0c638b185bf218f",
      "dee7cc90809b4b57a86dfa874671fbee",
      "b1f17e2a261f4630a7a615ffaa935c05",
      "b345c7f391a9405bbbc24450a71d2899",
      "71e55f67a13e42feaef690429d465765",
      "00327627928a4005a2f41cd2f4fe25a6",
      "d921c07b6cce43b78e04110b18dd5f2d",
      "681e117f315144d2837d85a18005c162",
      "7a9d6e54c3da4618a3dce685247aa81f",
      "4f7ca3b80ecb499f9a7d81f8e88f0239",
      "5393e0d04e6547d684ab28ae19a63980",
      "b2ab640597aa4ccbbc2f7c8ed2590110",
      "77c08f0cf8b4453880f58c7e96d200e6",
      "12c49a1e93f7456996a101fc141aad30",
      "79d625a17d124032869959e4f403996a",
      "06623ad9fb084619946f71ba6b0eed8f",
      "0ee00a2fc0e142a6a5f35a3481f1ea9e",
      "8131f7938748432ab4e040a8a48cb3c8",
      "3b90df73be40408eb49167774dfad2ef",
      "bd183fba95dd4000857b53042fba32a6",
      "21f85cea4ddf45a496963a069de97c39",
      "0bce412864ef4d52b8f1e392df2a8699",
      "83b49d48b23d464681568349e7275b14",
      "268ff3b06a694565bee73e0a0a5c70a3",
      "4bbf904a82ae4f549ca114358bebeb44",
      "75f796d518b9435e8f6dcb7fc9aacd1b",
      "cf7c0ab5fcdc4ab49572682eb99c2d1d",
      "f79e369282094357b1ded3bca1e54422",
      "b36a7475e14f45739d9c63f58501f144",
      "7be2ddb6f17b42c6972e79f270369930",
      "6a9dd5d36be24613bf6164359f48bc43",
      "5877db6e79db4ed39b08f21204e5914d",
      "8b054cdc1bce4c6ba35d7e27efb2c32c",
      "a170001229c349dc9e54ef57885af2d0",
      "710cdf32176942ce971a4e012820d9fb",
      "b43c79123c79468c8d51043a44ee5133",
      "52c4117818bb4583b221764695bd4fe7",
      "c19ccfebd23f424e84cfd2ddce144eb5",
      "77d2a1aa603b40d4aa2b4a27f1c06d42",
      "efee98e26f8c4f4cbe4dc8f9bc078f3a",
      "0370a79e65794e5baa386b86dab92a4e",
      "18638b1bc8274689b17192a0100ca2e8",
      "f5874818e8ca46f390a621c6b3dfa2c3",
      "314b148ec78c40ed915db74f21ea7181",
      "c6461799d30c48a1a8780d98a077262e",
      "83265822cb9d4f7ca6c74a6760a45e12",
      "d59b45aef10647189c14ffe56c253ad3",
      "ffa66ffbf0014ba285d14852b2fe52e3",
      "c871a206ce8d49a5aa45b9fadc67b7be",
      "c6b57bf4432f4f02a5ff5a8800b96eff",
      "0e4e4600dc604e24b643285a40212c77",
      "7342286ec9564b3f9f425941c04e83b9",
      "d0a887d481c040fc8ae8f1c19ca807ed",
      "f46ba10a786249c3a8bcbdf3c1b01fb4",
      "8dcaaf5c9b8641bdbf251ed6280f0e6e",
      "be878ecb64a1455ba40d1b94f309f67a",
      "75364a7449d74e4b8fe2dd5644682136",
      "803a20b43a084c71a1d4c0694de78230",
      "f65441663e434c9bbf6363ed9f12fdc5",
      "2892bab0d52640f4a171a5fb92218ab9",
      "c7d0daf1f3a64444a073d66cd6c8b4bf",
      "66862d4b5f414403adb7b5f9ffbc88fb",
      "0d1ec1f2835b4b31a94aed43f3c6b363",
      "ba241a572f5448bd8f99adc19be284e4",
      "798817440f3941849453a2b7a96b83ac",
      "4abfd31b5c4c4524a89cae8d981e0103",
      "880b217f6e514bcebfc29c8cf7804c55",
      "87297e18d45d403cbfbf412183445053",
      "b150fc70a54b4d29b927d28386016cb8",
      "d34fcac5dda445e183663bd3b228a546",
      "0325ebc153a84fb38d36ede4db53be7b",
      "0a6174c4944e4ca3bbab9cbd2ea18f16",
      "34df81476da245a7a34f6ac2be0449db",
      "47410d2915da440da185128219319aea",
      "8d82587af51740b892469b906ec3bb58",
      "6e86800caacb4232ab851438dced9bd0",
      "d7020f61da6d498e87d1a59b3b3b42db",
      "ac79df99a09044a2acfda24693a4eedb",
      "bdb24eba4c344d9093d22015ce33fb31",
      "3c2d059728f04e8ba1dbbf44674b45a7",
      "5eb6934d798e46f7b0ff0b54c23005c8",
      "504f62dc337d4820a9f05bf28a40d9c2",
      "a32c8279908546d5825c6e6e357dda4d",
      "8dd74338c6be4cf19a6a575e9749b66d",
      "11121e2a432c4e858480edc0752b7422",
      "04cfd7c714834a15ab2bad2496ab83da",
      "831f36ba766a44838ea0225082abfb66",
      "1ad7650e364d471795462ae5c7111101",
      "87bba9f6cdfd4d229149e5455ffb56ce",
      "de3407baa0f44aff8ae864138e0cc0ad",
      "57a7854e0faa47a48ac19fcedb2fc3d5",
      "c05028a20041419db43d16beba00b205",
      "a32e29db3fa44e51845c9c24e75a01d9",
      "c10cb1801ec646a5ad71de0fa762dec4",
      "b00a6d65c3d64497becd4d47b0ef6578",
      "fdb76f4b0c86420dad33f2fdd12984b8",
      "615a4b95727c4603b5c174e9761e3018",
      "6e52893add65433f992d05f60d0d536f",
      "5f29747da0424ea192018284e2bbebcf",
      "d02dce26ef2d42989c52262868f77397",
      "7ebf63c44c63437c932fddff81c7a47f",
      "741236bb1e954db794cec0614a759d6a",
      "080ae1c1ec2d422188b8f4451bff14f4",
      "803b9c54e2d34fd6b4dca6da6b873698",
      "8421e00f0be244e5b4f3075eeaacab72",
      "5f0343cc66f64a2f8552dee0be68c065",
      "87fef3179ef345e89003c64a20e36695",
      "1084cf1ce24648f09819de3dbb175503",
      "ddf45cf0fab7491f83bc970406bd5bd0",
      "072b093081a54075b1e6157c4394cf6a",
      "9cb43d38bbee4ca19ffd33b543664f2e",
      "ca02200f63434673b155036f57b16c60",
      "b3cbbc169216450eb370b42d39747c87",
      "a49ed3c97d5245599b3b85414db92463",
      "7a334eeee41f464991ee74e7b0ad2b9c",
      "1ba34baab58f461d901757edf5690637",
      "d9704d9340044cf4933b0545c5fba813",
      "b76a23eb584c4bfab55878d20316af64",
      "287e57d34d8842ab81621a979e8cd08d",
      "10e9e5459fa54d5bade716ecd3f50f89",
      "d1aceb40ff714efaa832c479674b532f",
      "85f004644181434cb68f4831a532168a",
      "95de0d5bc9844363aea182146dba5449",
      "d6198eba1b6e4801b81353104d72e101",
      "de817be744cc455387570f144c5e29b0",
      "e8fca86b1b4e40678d6fe1ced2c07580",
      "a251da944a67482b8eb299127948f54b",
      "263931eb4bd5416281bffa8eca8f75f5",
      "aee5badb5a244cb8ba1a4de2178c7cc0",
      "a743e74472444c17b629001960024994",
      "c3665cfb34bc45ddb90369c5b348ad73",
      "1f5ec54b0a3f480c9cfdf8e750a74853",
      "cca27736b7aa46408ff76e88012ca3c1",
      "dd18dbd981be4e30850cb282e64d3d1c",
      "14472883e829478aa50322208cf517ff",
      "46cca476cc5e4a06834425a45b239a7c",
      "46fa22c772cc4669a5aa645780306f15",
      "b022bd8643b04740b9ebdda70d0d10ae",
      "88d381417f9f47a7ae4bebcbb81b2d81",
      "feb402251f724aa1b8b68f6b4fe971c6",
      "fdce7c4aab9f4e54bf413ba54e85b19d",
      "c139f10903e941d78db7633bf273ec58",
      "0d9d70f04ccc4f0f98c351dcddbf5611",
      "acf18a4a8f844bc18118e1ac5c067b25",
      "e114816bd7a34cf794b63dba530324a3",
      "9436b4c2c3214ea38eb35832bc73efc0",
      "a6182f46acb84c67a702781c8538c392",
      "ea52f2f8273a40929a9f6d771e08eccf",
      "18c3517e49924b22af61d48559aee8c6",
      "f117ede3ea1b48148cff644e6c2c3420",
      "c91f449f8cea40c1bc1417823064e58d",
      "58de9e4f2dae4c3d82fcba5ebf226a93",
      "e45d73acadfc4bb59ae9cd1d4b5ab100",
      "acd62a7c61c34c26948d1d82d1d0eed1",
      "a9575e2d357646198e797cacf4cc1ad3",
      "b087a627611b45d786197ba61862e860",
      "d046d2ac5bfa403191e053f039544163",
      "dc821c6c88d94601a90d5ba8e89b2d2b",
      "7108d4c5a7e9484e9d02707bbd178d4d",
      "3bc900502b834cc9bd53d0f5222712cb",
      "31d9ce2205a440659dc78c3faec300da",
      "a934f5bac897447da4c00f5d66dda08a",
      "b406af36952d4622b324ff7200863d2e",
      "3f103f9151684da3b9b418d2e11cb7a4",
      "7aa9d8c4fbcf42c387fa714d46d85aad",
      "a18f21d7fa1b461388d2426a8d0cbe44",
      "3982f6b0879d4550913c982d22e1f558",
      "cf16496a071e42d48fa98278b9962f54"
     ]
    },
    "executionInfo": {
     "elapsed": 103557,
     "status": "ok",
     "timestamp": 1681139211306,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "GMR653amkfZp",
    "outputId": "3d0a5165-16e8-4cb3-ca5b-250f238a1e87"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c088bf04115a4e28981721906fb0feb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/4.00 [00:00<?, ?text generation/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b345c7f391a9405bbbc24450a71d2899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d625a17d124032869959e4f403996a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f796d518b9435e8f6dcb7fc9aacd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c4117818bb4583b221764695bd4fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa66ffbf0014ba285d14852b2fe52e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65441663e434c9bbf6363ed9f12fdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34fcac5dda445e183663bd3b228a546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb6934d798e46f7b0ff0b54c23005c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05028a20041419db43d16beba00b205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080ae1c1ec2d422188b8f4451bff14f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49ed3c97d5245599b3b85414db92463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de817be744cc455387570f144c5e29b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cca476cc5e4a06834425a45b239a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6182f46acb84c67a702781c8538c392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc821c6c88d94601a90d5ba8e89b2d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.8 s, sys: 6.66 s, total: 34.5 s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Warmup run to force all downloads.\n",
    "first_lines = ['\"I have spoken.\" he said.']\n",
    "df_warmup = generate_for(first_lines, device, ['t5_s1', 'opt_s2', 'b2b_s2', 'baseline'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "z6pXWfANgeE3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140,
     "referenced_widgets": [
      "2ee0a3beb0f04fd1b2e6570044c6b515",
      "26dc4b8f23a6414f9329ae1d7d15a8cc",
      "cccd32a114d7462eaaca5383475633f3",
      "ed0f02c3844343ee9f19c6bda553a324",
      "a16c8754d0914371bf7db3fd04768938",
      "665bf2616a8045e7825dd144ab95fbe6",
      "2a5e25b851d344c2a6303b2c3b9110b5",
      "e1eb9b9568e84fb58a7d1af3bdc3ad94",
      "ab86a5b461c540ddbddbc7dcffc0a4ff",
      "f5ac199231164edc8a747b8eb4f86e43",
      "0d3edc97ae374545a089c03e6c1f2812"
     ]
    },
    "executionInfo": {
     "elapsed": 234480,
     "status": "ok",
     "timestamp": 1681139965708,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "z6pXWfANgeE3",
    "outputId": "d4c6f346-e287-4937-c247-1eabbcb8b279"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee0a3beb0f04fd1b2e6570044c6b515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/18.0 [00:00<?, ?text generation/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 11.3 s, total: 1min 42s\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "first_lines = ['Lara felt very sad and scared.', 'All the dragons of the world lived on one mountain called the dragon mountain.']\n",
    "df_results = generate_for(first_lines, device)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pTF_5WE-d7rv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1681140306301,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "pTF_5WE-d7rv",
    "outputId": "eb8323c1-d900-4d0a-80d9-5d73b64e95b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0eaa0ee3-2d5e-4419-bc9a-02591a693b98\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>tuned</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prompt</th>\n",
       "      <th>score</th>\n",
       "      <th>generated</th>\n",
       "      <th>model_top_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>\"Are you going to do that?\" asked Lavinia.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>\"It is a pity that it is so old,\" she said.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>The old woman sat down and waited.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>\"You are so kind, sir,\" she cried.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>t5_s1</td>\n",
       "      <td>google/t5-v1_1-base-s1-finetuned</td>\n",
       "      <td>True</td>\n",
       "      <td>s1</td>\n",
       "      <td>Lara felt very sad and scared.</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>\"I'm afraid of her!\" she whispered.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>18</td>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>Continue the next sentence of the story making...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>18</td>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>Continue the next sentence of the story making...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>18</td>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>Continue the next sentence of the story making...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>18</td>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>Continue the next sentence of the story making...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>18</td>\n",
       "      <td>baseline</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>All the dragons of the world lived on one moun...</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>Continue the next sentence of the story making...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0eaa0ee3-2d5e-4419-bc9a-02591a693b98')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0eaa0ee3-2d5e-4419-bc9a-02591a693b98 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0eaa0ee3-2d5e-4419-bc9a-02591a693b98');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    batch_id      name                             model  tuned dataset  \\\n",
       "0          1     t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "1          1     t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "2          1     t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "3          1     t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "4          1     t5_s1  google/t5-v1_1-base-s1-finetuned   True      s1   \n",
       "..       ...       ...                               ...    ...     ...   \n",
       "85        18  baseline                 facebook/opt-350m  False    None   \n",
       "86        18  baseline                 facebook/opt-350m  False    None   \n",
       "87        18  baseline                 facebook/opt-350m  False    None   \n",
       "88        18  baseline                 facebook/opt-350m  False    None   \n",
       "89        18  baseline                 facebook/opt-350m  False    None   \n",
       "\n",
       "                                               prompt     score  \\\n",
       "0                      Lara felt very sad and scared.  0.000038   \n",
       "1                      Lara felt very sad and scared.  0.000031   \n",
       "2                      Lara felt very sad and scared.  0.000079   \n",
       "3                      Lara felt very sad and scared.  0.000033   \n",
       "4                      Lara felt very sad and scared.  0.000035   \n",
       "..                                                ...       ...   \n",
       "85  All the dragons of the world lived on one moun...  0.006471   \n",
       "86  All the dragons of the world lived on one moun...  0.002831   \n",
       "87  All the dragons of the world lived on one moun...  0.004651   \n",
       "88  All the dragons of the world lived on one moun...  0.006506   \n",
       "89  All the dragons of the world lived on one moun...  0.004662   \n",
       "\n",
       "                                            generated  model_top_score  \n",
       "0          \"Are you going to do that?\" asked Lavinia.            False  \n",
       "1         \"It is a pity that it is so old,\" she said.            False  \n",
       "2                  The old woman sat down and waited.             True  \n",
       "3                  \"You are so kind, sir,\" she cried.            False  \n",
       "4                 \"I'm afraid of her!\" she whispered.            False  \n",
       "..                                                ...              ...  \n",
       "85  Continue the next sentence of the story making...            False  \n",
       "86  Continue the next sentence of the story making...            False  \n",
       "87  Continue the next sentence of the story making...            False  \n",
       "88  Continue the next sentence of the story making...             True  \n",
       "89  Continue the next sentence of the story making...            False  \n",
       "\n",
       "[90 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.to_csv(common.annotation_input_loc(GDRIVE_BASE), index=None)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZqiupvHh7VmF",
   "metadata": {
    "id": "ZqiupvHh7VmF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UBU7IM3uc14g"
   ],
   "provenance": [
    {
     "file_id": "1qH9or9UvtJOb_mlSSHcRjZKwZT9uDwbl",
     "timestamp": 1680142704332
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Ne5-am8spATz",
   "metadata": {
    "id": "Ne5-am8spATz"
   },
   "source": [
    "# Fine Tuning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wHUaO6-oCKak",
   "metadata": {
    "id": "wHUaO6-oCKak"
   },
   "source": [
    "## Working With This Notebook\n",
    "This notebook needs following setup before it can run:\n",
    "- Have a project folder setup in google drive \n",
    "- A data folder under this project folder that has the train-val and test splits of all three datasets (total 6 csv files)\n",
    "- common.py, with common code and constants, copied to the project folder on google drive\n",
    "- GDRIVE_BASE below updated to point to the project foder on google drive\n",
    "- a GPU for efficient training and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97nY_nL9CeiJ",
   "metadata": {
    "id": "97nY_nL9CeiJ"
   },
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egOvt-Oq0M2J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37917,
     "status": "ok",
     "timestamp": 1680998887046,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "egOvt-Oq0M2J",
    "outputId": "ad961f1a-0a4d-477d-ac44-7d4d2012cbbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 sentencepiece-0.1.97 tokenizers-0.13.3 transformers-4.27.4\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/google-research/bleurt.git\n",
      "  Cloning https://github.com/google-research/bleurt.git to /tmp/pip-req-build-tqaaq0yc\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/google-research/bleurt.git /tmp/pip-req-build-tqaaq0yc\n",
      "  Resolved https://github.com/google-research/bleurt.git to commit cebe7e6f996b40910cfaa520a63db47807e3bf5c\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from BLEURT==0.0.2) (1.4.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from BLEURT==0.0.2) (1.22.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from BLEURT==0.0.2) (1.10.1)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from BLEURT==0.0.2) (2.12.0)\n",
      "Requirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.9/dist-packages (from BLEURT==0.0.2) (1.1.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from BLEURT==0.0.2) (0.1.97)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from tf-slim>=1.1->BLEURT==0.0.2) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->BLEURT==0.0.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->BLEURT==0.0.2) (2022.7.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (16.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (2.12.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (23.3.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (3.20.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (1.14.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (3.8.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (67.6.1)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (2.12.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (0.32.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (4.5.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (2.12.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (1.16.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (0.4.7)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (2.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->BLEURT==0.0.2) (1.53.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->BLEURT==0.0.2) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow->BLEURT==0.0.2) (0.0.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2.17.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2.2.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (6.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (3.2.2)\n",
      "Building wheels for collected packages: BLEURT\n",
      "  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for BLEURT: filename=BLEURT-0.0.2-py3-none-any.whl size=16456781 sha256=8f055d8a377ef3499909fea01ab1f41a1780ea8c3a8c23f0e3d78d4ed9e62ed4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-q8hnwkng/wheels/b0/2a/c4/2bd63eb0e30d711baac17dfc89ca58a876cac68b44a2c2a97a\n",
      "Successfully built BLEURT\n",
      "Installing collected packages: BLEURT\n",
      "Successfully installed BLEURT-0.0.2\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (67.6.1)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-ml-py3\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate) (1.22.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (2.0.0+cu118)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.10.7)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (16.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (3.25.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.4.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.4.0->accelerate) (1.3.0)\n",
      "Building wheels for collected packages: nvidia-ml-py3\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19188 sha256=fe7d17fe39a32fafd1aa80f7c0413e903153cb78ee62262b32a1ba71cfd7dd6d\n",
      "  Stored in directory: /root/.cache/pip/wheels/f6/d8/b0/15cfd7805d39250ac29318105f09b1750683387630d68423e1\n",
      "Successfully built nvidia-ml-py3\n",
      "Installing collected packages: nvidia-ml-py3, accelerate\n",
      "Successfully installed accelerate-0.18.0 nvidia-ml-py3-7.352.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting bertviz\n",
      "  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from bertviz) (2022.10.31)\n",
      "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.9/dist-packages (from bertviz) (2.0.0+cu118)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.26.109-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from bertviz) (4.65.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from bertviz) (2.27.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from bertviz) (0.1.97)\n",
      "Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.9/dist-packages (from bertviz) (4.27.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->bertviz) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->bertviz) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->bertviz) (3.1.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->bertviz) (3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->bertviz) (3.10.7)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->bertviz) (2.0.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0->bertviz) (16.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0->bertviz) (3.25.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.0->bertviz) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.0->bertviz) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.0->bertviz) (1.22.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.0->bertviz) (0.13.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.0->bertviz) (0.13.3)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.30.0,>=1.29.109\n",
      "  Downloading botocore-1.29.109-py3-none-any.whl (10.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->bertviz) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->bertviz) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->bertviz) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->bertviz) (1.26.15)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.30.0,>=1.29.109->boto3->bertviz) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.0->bertviz) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.0->bertviz) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.109->boto3->bertviz) (1.16.0)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, bertviz\n",
      "Successfully installed bertviz-1.4.0 boto3-1.26.109 botocore-1.29.109 jmespath-1.0.1 s3transfer-0.6.0\n"
     ]
    }
   ],
   "source": [
    "GDRIVE_BASE = 'drive/MyDrive/MIDS/w266/project/'\n",
    "\n",
    "!pip install transformers sentencepiece\n",
    "!pip install git+https://github.com/google-research/bleurt.git\n",
    "!pip install setuptools accelerate nvidia-ml-py3\n",
    "!pip install bertviz "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RtUED7nKSww0",
   "metadata": {
    "id": "RtUED7nKSww0"
   },
   "source": [
    "### Connect to Google Drive\n",
    "We will be loading data from google drive and also save trained models to google drive. So lets mount google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DvSvLEFgSxWH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24581,
     "status": "ok",
     "timestamp": 1680998911620,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "DvSvLEFgSxWH",
    "outputId": "b010e3f4-c365-451d-f314-cc0a8f61fd6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "sys.path.insert(0, GDRIVE_BASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5QyOXIFTC1kO",
   "metadata": {
    "id": "5QyOXIFTC1kO"
   },
   "source": [
    "### Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iyD4NJOTDDlt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10893,
     "status": "ok",
     "timestamp": 1680998922501,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "iyD4NJOTDDlt",
    "outputId": "eb93b951-4717-4b58-82bd-7751921ec101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common.__version__: 1.3\n",
      "torch.__version__: 2.0.0+cu118\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n",
      "Utilization at the beginning:\n",
      "CPU RAM Used: 1.7 GB\n",
      "CPU RAM Free: 87.1 GB\n",
      "GPU memory occupied: 449 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "Sun Apr  9 00:08:41 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0    45W / 400W |      3MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import AutoModel, AutoTokenizer, OPTForCausalLM, Trainer, TrainingArguments\n",
    "from pynvml import *\n",
    "import os,sys,humanize,psutil\n",
    "import gc\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch\n",
    "import time\n",
    "import common # Imported from common.py on google drive.\n",
    "from bertviz import model_view, head_view, neuron_view, transformers_neuron_view\n",
    "\n",
    "def free_gpu_ram():\n",
    "  with torch.no_grad():\n",
    "      torch.cuda.empty_cache()\n",
    "  gc.collect()\n",
    "  os.system('nvidia-smi -caa')\n",
    "\n",
    "def print_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(\"CPU RAM Used: \" + humanize.naturalsize( psutil.virtual_memory().used))\n",
    "    print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available))\n",
    "\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "    print('Using device:', device)\n",
    "    print()\n",
    "    if device.type == 'cuda':\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "\n",
    "# Display details about the environment.\n",
    "print(f'common.__version__: {common.__version__}')\n",
    "print(f'torch.__version__: {torch.__version__}')\n",
    "!nvcc --version\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Utilization at the beginning:')\n",
    "print_utilization()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JqnKi9o2_edx",
   "metadata": {
    "id": "JqnKi9o2_edx"
   },
   "outputs": [],
   "source": [
    "# Helper Methods and classes\n",
    "# Create torch dataset\n",
    "class T5InputDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets[\"input_ids\"])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_ids = self.inputs[\"input_ids\"][index].squeeze()\n",
    "        target_ids = self.targets[\"input_ids\"][index].squeeze()\n",
    "        attention_mask = self.inputs['attention_mask'][index].squeeze()\n",
    "        return {'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'labels': target_ids}\n",
    "\n",
    "class OptInputDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.labels = labels\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids']) \n",
    "\n",
    "def load_data(main_file, train_val_file, test_file, test_seed=common.SEED, load_splits_from_file=False, prompt='', include_test=False, train_size=-1, val_size=-1):\n",
    "  def save_to(x, y, file_name):\n",
    "    xy = {'variable': x, 'label': y}\n",
    "    df = pd.DataFrame(xy)\n",
    "    print(f'Saved {df.shape[0]} rows to {file_name}')\n",
    "    df.to_csv(file_name, index=False)\n",
    "\n",
    "  def load_from(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    df = df.astype({'variable':'string', 'label':'string'})\n",
    "    print(f'Loaded {df.shape[0]} rows from {file_name}')\n",
    "    return df['variable'], df['label']\n",
    "\n",
    "  if load_splits_from_file:\n",
    "    x_train_val, y_train_val = load_from(train_val_file)\n",
    "    x_test, y_test = load_from(test_file)\n",
    "  else:\n",
    "    x, y = load_from(main_file)\n",
    "    # Split the dataset into train (80%), validation (10%) and test (10%) datasets.\n",
    "    # Test data should be determinable.\n",
    "    x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, train_size=0.9, random_state=test_seed)\n",
    "    # Save train-val and test data separately.\n",
    "    save_to(x_train_val, y_train_val, train_val_file)\n",
    "    save_to(x_test, y_test, test_file)\n",
    "\n",
    "  # Split train and validation datasets.\n",
    "  x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, train_size=0.88)\n",
    "\n",
    "  if train_size > 0:\n",
    "    x_train = x_train[:train_size]\n",
    "    y_train = y_train[:train_size]\n",
    "  if val_size > 0:\n",
    "    x_val = x_val[:val_size]\n",
    "    y_val = y_val[:val_size]\n",
    "\n",
    "  if prompt is not None and len(prompt) > 0:\n",
    "    x_train = prompt + x_train\n",
    "    x_val = prompt + x_val\n",
    "    x_test = prompt + x_test\n",
    "\n",
    "  if include_test:\n",
    "    return x_train, x_val, y_train, y_val, x_test, y_test\n",
    "  else:\n",
    "    return x_train, x_val, y_train, y_val\n",
    "\n",
    "def t5_datasets_provider(config, x_train, y_train, x_val, y_val):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(config.base_model)\n",
    "  tokenize = lambda data: tokenizer(\n",
    "    list(data),\n",
    "    max_length=config.max_len,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt')\n",
    "\n",
    "  # Tokenize data\n",
    "  x_train_tokenized = tokenize(x_train)\n",
    "  y_train_tokenized = tokenize(y_train)\n",
    "  x_val_tokenized = tokenize(x_val)\n",
    "  y_val_tokenized = tokenize(y_val)\n",
    "  # Create and return datasets\n",
    "  training_set = T5InputDataset(x_train_tokenized, y_train_tokenized)\n",
    "  validation_set = T5InputDataset(x_val_tokenized, y_val_tokenized)\n",
    "  return training_set, validation_set\n",
    "\n",
    "def opt_datasets_provider(config, x_train, y_train, x_val, y_val):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(config.base_model)    \n",
    "  tokenize = lambda data: tokenizer(\n",
    "      list(data),\n",
    "      padding=\"max_length\",\n",
    "      truncation=True,\n",
    "      max_length=config.max_len,\n",
    "      return_tensors='pt')\n",
    "  x_train_tokenized = tokenize(x_train)\n",
    "  x_val_tokenized = tokenize(x_val)\n",
    "  training_set = OptInputDataset(x_train_tokenized, x_train_tokenized['input_ids'])#, y_train_tk['input_ids'])\n",
    "  validation_set = OptInputDataset(x_val_tokenized, x_val_tokenized['input_ids'])#, y_test_tk['input_ids'])\n",
    "  return training_set, validation_set\n",
    "\n",
    "def t5_trainer_provider(config, training_set, validation_set, device):\n",
    "  # Create trainer\n",
    "  model = T5ForConditionalGeneration.from_pretrained(config.model_name).to(device)\n",
    "  print(f'Utilization after loading model {config.model_name}:')\n",
    "  print_utilization()\n",
    "\n",
    "  args = Seq2SeqTrainingArguments(\n",
    "      output_dir='checkpoints',\n",
    "      evaluation_strategy='epoch',\n",
    "      save_strategy='epoch',\n",
    "      per_device_train_batch_size=config.train_batch_size,\n",
    "      per_device_eval_batch_size=config.val_batch_size,\n",
    "      num_train_epochs=config.epochs,\n",
    "      load_best_model_at_end=True,\n",
    "      save_total_limit=common.CHECKPOINTS_TO_SAVE,\n",
    "      optim='adamw_torch',\n",
    "      learning_rate=3e-4,\n",
    "      # gradient_accumulation_steps=4,\n",
    "      # fp16=True,\n",
    "      bf16=True,\n",
    "      tf32=True\n",
    "  )\n",
    "\n",
    "  # Define the trainer, passing in the model, training args, and data generators\n",
    "  trainer = Seq2SeqTrainer(\n",
    "      model,\n",
    "      args,\n",
    "      train_dataset=training_set,\n",
    "      eval_dataset=validation_set\n",
    "  )\n",
    "  return trainer\n",
    "\n",
    "def opt_trainer_provider(config, training_set, validation_set, device):\n",
    "  model = OPTForCausalLM.from_pretrained(config.model_name).to(device)\n",
    "  training_args = TrainingArguments(\n",
    "      output_dir='checkpoints', \n",
    "      evaluation_strategy=\"epoch\",\n",
    "      save_strategy=\"epoch\", \n",
    "      per_device_train_batch_size=config.train_batch_size,\n",
    "      per_device_eval_batch_size=config.val_batch_size,\n",
    "      num_train_epochs=config.epochs,\n",
    "      load_best_model_at_end=True,\n",
    "      save_total_limit=common.CHECKPOINTS_TO_SAVE,\n",
    "      optim='adamw_torch',\n",
    "      # learning_rate=3e-4,\n",
    "      # # gradient_accumulation_steps=4,\n",
    "      # # fp16=True,\n",
    "      # bf16=True,\n",
    "      # tf32=True\n",
    "    )\n",
    "  trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=validation_set,\n",
    "    compute_metrics=None,\n",
    "  )\n",
    "  return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CzqQ3uHdCkdF",
   "metadata": {
    "id": "CzqQ3uHdCkdF"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F94Z34ZEBLDz",
   "metadata": {
    "id": "F94Z34ZEBLDz"
   },
   "outputs": [],
   "source": [
    "tuning_configs = common.create_configs(GDRIVE_BASE, t5_trainer_provider, t5_datasets_provider, opt_trainer_provider, opt_datasets_provider)\n",
    "\n",
    "def train(config, device):\n",
    "  # Load the data\n",
    "  x_train, x_val, y_train, y_val = load_data(\n",
    "      config.main_data_file, config.train_val_data_file, \n",
    "      config.test_data_file, test_seed=common.SEED, \n",
    "      load_splits_from_file=True, prompt=config.prompt, include_test=False,\n",
    "      train_size=config.training_samples, val_size=config.val_samples)\n",
    "  print(f'x-train shape: {x_train.shape}, x-val shape: {x_val.shape}, y-train shape: {y_train.shape}, y-val shape: {y_val.shape}')\n",
    "\n",
    "  # Get the dataset objects.\n",
    "  training_set, validation_set = config.datasets_provider(config, x_train, y_train, x_val, y_val)\n",
    "  \n",
    "  # Get trainer.\n",
    "  trainer = config.trainer_provider(config, training_set, validation_set, device)\n",
    "\n",
    "  # Train the model.\n",
    "  st = time.time()\n",
    "  result = trainer.train()\n",
    "  et = time.time()\n",
    "\n",
    "  # Print training summary\n",
    "  elapsed_time = et - st\n",
    "  print_summary(result)\n",
    "  print('Utilization after training: ')\n",
    "  print_utilization()  \n",
    "  \n",
    "  # Save the tuned model\n",
    "  trainer.save_model(config.tuned_model_path)\n",
    "\n",
    "  # Post training cleanup\n",
    "  del trainer, training_set, validation_set, x_train, x_val, y_train, y_val\n",
    "  free_gpu_ram()\n",
    "  print('Utilization after post training cleanup: ')\n",
    "  print_utilization()  \n",
    "  print(f'{\"*\"*25}Training took {elapsed_time} seconds {\"*\"*25}')\n",
    "\n",
    "def get_config(model_family, dataset):\n",
    "  if model_family not in common.VALID_MODEL_FAMILIES:\n",
    "    raise Exception(f'Model family {model_family} is invalid')\n",
    "  if dataset not in common.VALID_DATASETS:\n",
    "    raise Exception(f'Dataset {dataset} is invalid')\n",
    "  return tuning_configs[f'{model_family}_{dataset}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B5ym-VcTs0Ty",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a3e0d95df2a44c679eaf9f553ce407c2",
      "5fde76e6dd964333b5de286a53e504bf",
      "1a383345d34d4ea5a7c073aae4b5116c",
      "be95750bbb7544da9724f6d227e64fe4",
      "f306ff8b193743ec9ac138280f10e938",
      "4c3b7fcf7df2422aa3ada4c73ad73b78",
      "f7b78e091ac946f683d5410f05a52381",
      "992090195f8e4d5db99276622e34e6e7",
      "8014d82c0d01429f8b94088b2b014823",
      "5736a64ab1144cc6939e88bd124eea32",
      "0453a94ff4da4cda82d1e2309b0b5260",
      "e825f48701ce4813b60219847470de19",
      "69807029cb2f48f2a2bcaffc4242e914",
      "c7bec846099a41c3bd2ecffbfaad347a",
      "57d7269624b840b0849fa718e1d8b0f8",
      "e131ea54d8584a86a3ad1659a7ae80e4",
      "02a0f742dd664e269f474c09e8a24e60",
      "6f98e325f87a470d8a4359ab86452138",
      "486e89cd7e2e4c5b8e4275e53b318072",
      "f56a481a5ddb41a18519d0b6f7cf58a8",
      "d720f75ea51946f0ae3d7438b195d6fd",
      "0d6f80904a764846a6c856e11e7da16d",
      "ae71b94394034d2989615240175fcddd",
      "63f0f6d908de47b694e96df9d0d4ede3",
      "0ee9e9c9bd5b4def80463ad855574713",
      "8f7fe611ea374b2ab2498cd84e833daa",
      "f3ce64ac9fbf4f43a6f8186dab64bf39",
      "cc9e8c27ea5a40ccacef38eee0b1b5e1",
      "ea27306f465b4bc18df0702944d6a755",
      "3389747b19b14ec5aee04b9ed58ab0e6",
      "ce15bdbc416c409889e4b4e890ae579a",
      "8385dbb2ff55414cbf44f7afbfa587a1",
      "74ae10adfb71440ca734b3e9fc7e3f88",
      "c25006c7d9bd4201ab369622bda75d41",
      "a3c654a8ea36457c9b21cbf5e7382b05",
      "90629d11cfe848ae8aa040277d78445b",
      "4d93444239d84d5cb001128b85f9cc71",
      "74eb471081da43da992da7a353c521c0",
      "4cbc9754a78749a490d84d1e5648ab3d",
      "1bbd1f2bf1fb4b80b6c37a19df609d15",
      "fac8b828824b441b99aaa74847231700",
      "9146486e17f148a1a45cef0c3ff8f0f4",
      "caf36d0cde9f4c3f8ba13f8b21c56746",
      "dbbe200c08ed41a094de1f4114425e81",
      "a2b611ebea144b2aac011a16d6e9a591",
      "d6622a1582844b83878fed9b5e5df5b0",
      "f111822299874757bf89eee4b84cc8cf",
      "85196a8a384748aa861aed73e2e84bd7",
      "7fffda7ef2574f8ea3fdeaadc200c162",
      "1f602a39688c48a8b7bbd3764014f9b8",
      "f1ce0bdef8a04a0c90f7ae074e558be1",
      "98ef2eee217949faa4e2b386b36a637d",
      "7c9887a7c7d84821bcdce13daa2baab6",
      "5faeef844ce34e3bbc2c6b44a05d6f75",
      "0aaece87e43a4fa8a99bbc536e4af70a",
      "dc84db3f3f794eedabbda8c86f7f6a10",
      "d5e117f2c5b2438db597c4a9a33d9ca6",
      "1157d1a727444307a8264a2d75e52458",
      "094dc0a898e347248e126dbf609dcc85",
      "e7e2625f53bc42509f42d91a50d30487",
      "b0985f09c11e44929839a04229f26065",
      "1c8bdb30f6434e0e888099d56ba76fc5",
      "456ed1e951b14b99b6a88f50fe1169f6",
      "96c3956e1b4e4f41ad96abc18719b6f9",
      "15a792703499415c8fdf507076fc3380",
      "90676294875345bca4713a680b1ebb1b"
     ]
    },
    "executionInfo": {
     "elapsed": 1424297,
     "status": "ok",
     "timestamp": 1680897654867,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "B5ym-VcTs0Ty",
    "outputId": "9d21ab07-a6f6-488f-cac1-1c10a13f535f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************Training model T5 on S1 *************************\n",
      "Loaded 185571 rows from drive/MyDrive/MIDS/w266/project/data/posptproc_corpus_spacy_s1_train_val.csv\n",
      "Loaded 20619 rows from drive/MyDrive/MIDS/w266/project/data/posptproc_corpus_spacy_s1_test.csv\n",
      "x-train shape: (163302,), x-val shape: (10000,), y-train shape: (163302,), y-val shape: (10000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e0d95df2a44c679eaf9f553ce407c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e825f48701ce4813b60219847470de19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae71b94394034d2989615240175fcddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25006c7d9bd4201ab369622bda75d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b611ebea144b2aac011a16d6e9a591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc84db3f3f794eedabbda8c86f7f6a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilization after loading model google/t5-v1_1-base:\n",
      "CPU RAM Used: 7.6 GB\n",
      "CPU RAM Free: 81.2 GB\n",
      "GPU memory occupied: 2443 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.9 GB\n",
      "Cached:    1.0 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3828' max='3828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3828/3828 21:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.526900</td>\n",
       "      <td>1.347923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.427000</td>\n",
       "      <td>1.307112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.386600</td>\n",
       "      <td>1.277318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1299.28\n",
      "Samples/second: 377.06\n",
      "Utilization after training: \n",
      "CPU RAM Used: 7.8 GB\n",
      "CPU RAM Free: 81.0 GB\n",
      "GPU memory occupied: 29263 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 2.8 GB\n",
      "Cached:    26.8 GB\n",
      "Utilization after post training cleanup: \n",
      "CPU RAM Used: 7.8 GB\n",
      "CPU RAM Free: 80.9 GB\n",
      "GPU memory occupied: 5573 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    3.7 GB\n",
      "*************************Training took 1299.3015291690826 seconds *************************\n",
      "CPU times: user 20min 31s, sys: 2min 22s, total: 22min 53s\n",
      "Wall time: 23min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'{\"*\"*25}Training model T5 on S1 {\"*\"*25}')\n",
    "train(get_config('t5', 's1'), device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kmEumoJy2SVY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "executionInfo": {
     "elapsed": 2248766,
     "status": "ok",
     "timestamp": 1680899903617,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "kmEumoJy2SVY",
    "outputId": "37279d84-e97f-45bb-db33-ab0bf923bb0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************Training model T5 on S2 *************************\n",
      "Loaded 185134 rows from drive/MyDrive/MIDS/w266/project/data/posptproc_corpus_spacy_s2_train_val.csv\n",
      "Loaded 20571 rows from drive/MyDrive/MIDS/w266/project/data/posptproc_corpus_spacy_s2_test.csv\n",
      "x-train shape: (162917,), x-val shape: (10000,), y-train shape: (162917,), y-val shape: (10000,)\n",
      "Utilization after loading model google/t5-v1_1-base:\n",
      "CPU RAM Used: 11.4 GB\n",
      "CPU RAM Free: 77.3 GB\n",
      "GPU memory occupied: 5573 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.9 GB\n",
      "Cached:    3.7 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7638' max='7638' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7638/7638 36:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.885800</td>\n",
       "      <td>0.806105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.822700</td>\n",
       "      <td>0.752668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.795100</td>\n",
       "      <td>0.740657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2202.92\n",
      "Samples/second: 221.87\n",
      "Utilization after training: \n",
      "CPU RAM Used: 11.4 GB\n",
      "CPU RAM Free: 77.3 GB\n",
      "GPU memory occupied: 26715 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 2.8 GB\n",
      "Cached:    24.3 GB\n",
      "Utilization after post training cleanup: \n",
      "CPU RAM Used: 11.5 GB\n",
      "CPU RAM Free: 77.3 GB\n",
      "GPU memory occupied: 6029 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    4.1 GB\n",
      "*************************Training took 2202.9289886951447 seconds *************************\n",
      "CPU times: user 35min 6s, sys: 3min 17s, total: 38min 24s\n",
      "Wall time: 37min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'{\"*\"*25}Training model T5 on S2 {\"*\"*25}')\n",
    "train(get_config('t5', 's2'), device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gwEgCdeS2Su6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "70ff0c9335db4996869ec8b5654408fd",
      "2215c00f39eb4125ad5d0e9e6bb2428e",
      "e7b3fddf9ce74556980fde9d95134840",
      "0d7ef18c9d2c42a1aadc39d7cb77d490",
      "b7f7503b0ca54377900f44d38c0c2eec",
      "e50f715609e74ddfb30388b14d1b70e8",
      "8febd6e9a20045fc90fd3c40c3d1cb73",
      "a172c450f62e40b793bef67a317e3e1b",
      "5b3a0fb8b70a4b35a00f7cefe930ef3f",
      "ee6207ca495d41819d5acd26170fee2b",
      "a1ff2eaf893745408dd39208e3c21e97",
      "1cadc62a940342a4a2b204409b5e1b5e",
      "e7857e554b094c5d8013b74eaadfbd3f",
      "68083038683b4f44a6378ac4bd4857a5",
      "1d3890456ddf4e8187598a0a6971a2a7",
      "8a6ed281af234a8f878731fe27468236",
      "9836d8c9fbd34c5aa11030ec34936235",
      "cfa9bf1e4e694ce08440c3a5895bc464",
      "f6d17cae012f443bb32f4fe287dbdb70",
      "3a07f056596b47e9a241bb7a2ad25b4a",
      "60b637b95ee34645861b567fa6448a85",
      "01aee5364bee4ed8bb754d62b5ba224f",
      "e07f8b629f92456385a004abc687dab6",
      "b3565d38700b4920a5d2b8f0361f1b15",
      "5365b4ac95fa44f7b62d2c0f40b4282a",
      "37231699518940cb8118009e2615a661",
      "7451b1f99ad848388738328733598113",
      "73e40bb21b2d4451b919284bd3237552",
      "122f4ef7e9f7493198031e2e83f05333",
      "6a17e7147938423380edfd37271bbc49",
      "e027865a19964ce8a907b858ca12497d",
      "48f5270414ca43ca91be46329c2b73b0",
      "12333619a18b402dafcba7f2a453dc12",
      "d0c5748c388445eda340b15646d9f572",
      "2561ab5faf904ce9a05b69ff9ac3c42d",
      "daf1f35bc651471199384daa9c8ef3cd",
      "c14fb16c50344d98a1419e0f5259f70e",
      "5132f8b120714d0db7df50b9cd1089e0",
      "23d3e6db3b59458584b6580c7ff0ec54",
      "49a1b7e169e7474bbdf5c002c0451eb3",
      "c9322c4a065a4706b0298226763756ed",
      "726dc72538d1427e9f71705044888faf",
      "a210467ae9d54fd5bea41c676f43e8ae",
      "d9f0519479254642a446d1258578313b",
      "b2b37390a22f4e67839b5fcd18819da5",
      "44df7cd900af4c57a141403a57c39959",
      "0fc807305a0041c4ac327cb519b9053a",
      "8fb631ddcc5f4eaeb63a1bfe3bf439cd",
      "9c63a30c45b040b39e1298e44f199cc4",
      "14b618993380441cba61762805056c65",
      "88744957e3ec4ca4992cf50bf0f8bf3b",
      "7790e79f9fed4d5fb3f3dafd899b63db",
      "0131437e80074884a5f84f2d71034a1d",
      "b27a37572f4b4a7eb4c01e2308104836",
      "1e49cf9f274c4ccd8ab7987b71e9a0d3",
      "ae3f60d12cd34eb89514cc1fc74a7522",
      "0dd18c78a70642478cca04c326275ac7",
      "9292cc7549f541ffbf0f831798f34b94",
      "486e8ebd8e264318b88e121119922d6c",
      "6f964d4e10fa4319abe601ed8483e74e",
      "f608a2525ace4060b7e6e9b048558b2d",
      "97875abfd79e47cb9c8b8efdcd177711",
      "43b85d81fca34c4f8b2f89b8b57a1efc",
      "d1aefad40ee54b15b2a6d281f4ce6c12",
      "44dc33e975a54b7eab2bbcc1ff5cc9d4",
      "00861ae21fc24d58866d3f28cfb6a407"
     ]
    },
    "executionInfo": {
     "elapsed": 2980101,
     "status": "ok",
     "timestamp": 1680904377124,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "gwEgCdeS2Su6",
    "outputId": "0356eb82-fe31-4bd0-dd68-0945340a475a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************Training model T5 on S3 *************************\n",
      "Loaded 184700 rows from drive/MyDrive/MIDS/w266/project/data/posptproc_corpus_spacy_s3_train_val.csv\n",
      "Loaded 20523 rows from drive/MyDrive/MIDS/w266/project/data/posptproc_corpus_spacy_s3_test.csv\n",
      "x-train shape: (162536,), x-val shape: (10000,), y-train shape: (162536,), y-val shape: (10000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ff0c9335db4996869ec8b5654408fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cadc62a940342a4a2b204409b5e1b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07f8b629f92456385a004abc687dab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c5748c388445eda340b15646d9f572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b37390a22f4e67839b5fcd18819da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3f60d12cd34eb89514cc1fc74a7522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilization after loading model google/t5-v1_1-base:\n",
      "CPU RAM Used: 11.4 GB\n",
      "CPU RAM Free: 77.4 GB\n",
      "GPU memory occupied: 2443 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.9 GB\n",
      "Cached:    1.0 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7620' max='7620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7620/7620 48:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.620100</td>\n",
       "      <td>0.559855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.589600</td>\n",
       "      <td>0.545220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.569400</td>\n",
       "      <td>0.540078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2902.53\n",
      "Samples/second: 167.99\n",
      "Utilization after training: \n",
      "CPU RAM Used: 12.1 GB\n",
      "CPU RAM Free: 76.6 GB\n",
      "GPU memory occupied: 35517 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 2.8 GB\n",
      "Cached:    32.9 GB\n",
      "Utilization after post training cleanup: \n",
      "CPU RAM Used: 11.6 GB\n",
      "CPU RAM Free: 77.1 GB\n",
      "GPU memory occupied: 5103 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    3.2 GB\n",
      "*************************Training took 2902.5436878204346 seconds *************************\n",
      "CPU times: user 43min 39s, sys: 6min 56s, total: 50min 35s\n",
      "Wall time: 49min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'{\"*\"*25}Training model T5 on S3 {\"*\"*25}')\n",
    "train(get_config('t5', 's3'), device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QKqUoDag8AVw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 911,
     "referenced_widgets": [
      "ffdce079f0a240c18a833ae5ac6373ab",
      "513cc30ce61c4b96b725772ed436970e",
      "e4208838a90a40b4848afec4f2eca47f",
      "041e8a3814d74a35b52e7e469791df4d",
      "3e2067ca7cf54ff9bdfb435f82c25f25",
      "e823172f8a3c40ec8718bb8af0a01756",
      "bbbc1e6c70d94176b36c5cb9fa75e1a8",
      "92365196389d4e62b4b9eb405ff4edc2",
      "c3e9be212ef64fc1bacd1709b426d4d8",
      "cdbb67fb782b472a89cdf431c4c479ff",
      "7c03d13f01d34ab89b5b5ebfa0bceece",
      "65801fa04d4d4f50920463f378e97385",
      "d5f63d4d00f94e848676abb1adcc6261",
      "794d7c2cf7e3445292213d04b7216c74",
      "c70d05a4acfd40b4967956f301587662",
      "7077bb3ee0694ea28599d553293b02f4",
      "0692904c4c8b48fda80b66cb03048968",
      "df7b458defa241d382ff331a9adb832c",
      "c9da6aa51e584a81a170555bd54831bb",
      "3968b535ba2444648c94834112cb7695",
      "801660bf7220429dbdd6fc3b736a33d8",
      "09f887c4450e4b13b9ec9474884b7347",
      "9c285da35de841c8aba8670bbedecf44",
      "74bd71e93d6044fcac60020a6bceedf5",
      "89b188c2b15343d7a81ccc8e3ad5e224",
      "5b65d79466564e5d878e12954d749aa4",
      "89dd30b94d934b48a76f57aee6bc3c10",
      "43fe3d11a953477faf0becb00f550b33",
      "900bc9e2658d4586af6ac7793c9c9c31",
      "99e4182d88494ba8ac6680e0c5af8408",
      "23acc7c7aac34ad593197ecd7022574f",
      "69d29e8d885544c9b3fe9484436bad46",
      "d340c1e962f84cadbc0007a7d834836a",
      "1671661ef3a24e4080fa4b1879414484",
      "1329ab5d9b1b456fb2c67dfaf2a24dba",
      "fe8befe469ba44e18941e136ff6bc039",
      "8526a95247d24c3cb87b00651568b6a9",
      "eea2977df369479b8af182a44548b232",
      "228376bce7be439cadcbf846e8914b43",
      "e97e40661a0749cc95359fcf70b01bdb",
      "e7b9efa8f3324248b10ae2c3b25d1902",
      "241efd2d1e3345f48bd251ab1031e4b2",
      "77da529691004fda9510d06f3a6a34c4",
      "6150a4999e1e4b57b4c0d6eca2d4fc27",
      "290a9bb79b294ec29752b36d819ffe89",
      "781ba458e92d49c6826cdd008e48aa1a",
      "49da9d98489241ccae2d4257943da190",
      "51212805002a4b1ca388ee0fc457f298",
      "6bb11333b1954350b2c136b596c79b2b",
      "0371fba45b5643d8b8604d96987613c9",
      "d19914a4427c4608abaa0572959f796e",
      "73ee896d71a24e82a0ac4d36114f962e",
      "280ce615b8ff4cae8924f98015d71172",
      "2eb09a0a31a94d0bbdb30772d4587480",
      "1904eb0dda8a4aa78e433c7f7c44c33e",
      "83e73fe4a9234d49a573c0759a4dd730",
      "ac8daadd222b4bb58d0c609ef3bb7084",
      "47c5ab151e9248079ccbc6bf36e7dc23",
      "2eec18ea98c743c0adadc495b6a0e435",
      "fd2ffd00a4a445939107b99aeef3ee3c",
      "0d24bc2cb08042098af429877e73574f",
      "1f18456afa31432785b5258b92646d35",
      "2d7fac94bd4f4ae2bec5e3436d065651",
      "192882342e154c8a87aa4f398829f7c8",
      "d39daaf40be14a6eaa868f67a634cae8",
      "409d4e4077d84641b86359f5736e9ada",
      "40bf5c63bb2b401480801e7d50f54745",
      "ec7c46175e134b198cf351d3d99ed215",
      "f47c7c0eec5b481ba8f5a43f16d9d773",
      "207d307f053f4de198d10adbe744cc98",
      "5a2f367763434414b655d101e1d03370",
      "b2c725775e14480a8f8c2c42d961a6af",
      "4264fff70f0348d08e148c8f3a921a64",
      "1367929aa2164e66bd10a8939b840960",
      "938939cf5c12417a84dc9ba106eb7c16",
      "5f004fb54fd241c38b1425882922c4a9",
      "73daf02d5246448e95969927c177c41d"
     ]
    },
    "executionInfo": {
     "elapsed": 2305449,
     "status": "ok",
     "timestamp": 1680907531409,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "QKqUoDag8AVw",
    "outputId": "ceccc442-50e7-44a0-cc22-53dc6003a12a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************Training model OPT on S2 *************************\n",
      "Loaded 185134 rows from drive/MyDrive/MIDS/w266/project/data/posptproc_corpus_spacy_s2_train_val.csv\n",
      "Loaded 20571 rows from drive/MyDrive/MIDS/w266/project/data/posptproc_corpus_spacy_s2_test.csv\n",
      "x-train shape: (162917,), x-val shape: (10000,), y-train shape: (162917,), y-val shape: (10000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdce079f0a240c18a833ae5ac6373ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65801fa04d4d4f50920463f378e97385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c285da35de841c8aba8670bbedecf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1671661ef3a24e4080fa4b1879414484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290a9bb79b294ec29752b36d819ffe89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e73fe4a9234d49a573c0759a4dd730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bf5c63bb2b401480801e7d50f54745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7638' max='7638' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7638/7638 37:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.394800</td>\n",
       "      <td>1.348230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.232100</td>\n",
       "      <td>1.271752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.119300</td>\n",
       "      <td>1.242142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2250.43\n",
      "Samples/second: 217.18\n",
      "Utilization after training: \n",
      "CPU RAM Used: 11.2 GB\n",
      "CPU RAM Free: 77.5 GB\n",
      "GPU memory occupied: 26089 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 3.7 GB\n",
      "Cached:    23.7 GB\n",
      "Utilization after post training cleanup: \n",
      "CPU RAM Used: 11.2 GB\n",
      "CPU RAM Free: 77.5 GB\n",
      "GPU memory occupied: 1835 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "*************************Training took 2250.4350945949554 seconds *************************\n",
      "CPU times: user 37min 37s, sys: 6min 5s, total: 43min 42s\n",
      "Wall time: 38min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'{\"*\"*25}Training model OPT on S2 {\"*\"*25}')\n",
    "train(get_config('opt', 's2'), device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mmUgxJFlVIeA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 911,
     "referenced_widgets": [
      "fddc00e09257486caeafdb12d3c6f042",
      "dcb8bc754c304bfb8e385bdbf94a90ff",
      "ba858ac119a546529a6194c58d4f6d1d",
      "c898a3eb7582459e8c0dd9d32ed6d297",
      "18e5c48c30a744b09127563c9ce185da",
      "cb3823254ae54a4a9537e1b541f19ecd",
      "418e23b1cd04493ca8c1b248476282b5",
      "435682ea2a6842c5abe63a4c6f7cac14",
      "9208328374c14ef9baab8792c597a318",
      "34262949440d41baabfc85c93560cbc2",
      "b51bc5f1e10d4daf8baf710180a265c4",
      "2b70f7a99a6e4f25ae06cd907335b142",
      "ad851ca924594fd2af8bfd2e7d98f3bd",
      "444613c4eda944dcb149e0a688039514",
      "9e8dbb4c81044c98a6fa2e3b76596bc9",
      "d07fe665d0b145fe88399de63661b0e5",
      "069dc76b0d3b47d99138b14dd0bc91d0",
      "1b2f3b6894f5492f9dc0a0816a5d1369",
      "78e353980ea34772a28a205009a63d09",
      "abb932f0802449d5b5b75b5978d379eb",
      "5e211b8a60654e93ab0ca57269564e96",
      "466fca7104c34e2d9eda45095607b4db",
      "dffe4b2d93384a9e996880c6cb945af8",
      "f35799b492e64b709ef979c83da4d59d",
      "eed6a7d51a7d40858190563b4dc12a81",
      "24d069ef648145f1bccb3913dcfdbd4b",
      "c5ae3c9bf58e414386fcf27ae8b52fd3",
      "6ff1a243b5a44d2d800c4c79d82af94f",
      "664791edbb0c4965a5126e32b30268ac",
      "06642681c2b04610bd3b17409199d287",
      "813c1e7c91f64f7690e36188adfe044e",
      "2f19967034144b1b849aad988c9b1cd0",
      "7dd468b2de454eb7927ab29ca78403c7",
      "69922bf0130340bba2ee011abc2a6768",
      "846acba9a2cc4523b53517c390752304",
      "26abd02cf94a4c10aea86e44d3b4296b",
      "812437ec340b463787d8b5b82d41fc48",
      "dfb001c2917e44cda104a084f4b9d778",
      "37b099562858471e849b2446590cee39",
      "d99aa34e134a4e4e9bd7ba11a07d6480",
      "af8bc0390df44b44924e64d0a342e717",
      "24d6d3be354f4360ba94f954d41405f8",
      "89329644865841098e1b5390eba45766",
      "f803431102304aa0be6f7da3a25aaadf",
      "b6a81cbcf8ac4f78943e1b518937916f",
      "5c76993a46e2490589550944ea2ace3a",
      "92c33195534147ef92f7e48394d6001a",
      "bf2bbcbbaa304f59aab83f76299a7d32",
      "b23611e98cbc4ec680583ac2d9443410",
      "e385d5ecb8f141d594337d044ef0f66d",
      "c2282b16bf8b44b2a7b8eb375f8751b9",
      "340ceb961e144b728203f5a2a8cf6758",
      "0a8466a2a7b74106bbb75a27d9b44bb6",
      "db0efaec2ce14b2ebe44845f206d1d4a",
      "873cdea092f54fffa9ce55db60ff8a82",
      "b24363c0431f41bd812acff3f7a739bf",
      "92e3d7493e3b4661aabbc910c767d7f9",
      "e71ac4d539b54d88b9b728ee5c5a24e0",
      "6f1b0dcd27734b4cbcd624b02b111dc3",
      "12a1ac762acf49169f0d4789d233311b",
      "fddf37ed2e49482c98b322aa788baefd",
      "a6832644192e4fca8121d9748a6acc4f",
      "66784a6838ba4c899fdf14f1eff247f2",
      "41e57313a30b42b89362f2b0add5d033",
      "ac1e2f3af7db4bacb361731b95ecaea6",
      "59ba610de1fc4108a0499400de8864e7",
      "8327816779384490b9c0c8863bcb0d62",
      "cab2e1b24de44379a50cb9c722ee3286",
      "942999c9bb2449ab856f2c180f51f756",
      "527cb50411cc43bc88ace3d542fede53",
      "af7cc64a37174dd399ceb4dd76b19ca8",
      "6a2ef7644d124794ba25d205e802c193",
      "28d1db09da8a417ba4b9584f6bf2ac3f",
      "b951c95ad23a4e8eaada877957957cf5",
      "f70e079cf7cd449688656c141d13aeee",
      "5b7e26885de4436e84f17f2eea140fac",
      "0bd037d21a1f4f64a9c04ee42ef97d87"
     ]
    },
    "executionInfo": {
     "elapsed": 10124945,
     "status": "ok",
     "timestamp": 1681009084274,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "mmUgxJFlVIeA",
    "outputId": "6b15cf5c-b117-437c-ac5b-a31073a3aa76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************Training model OPT on S3 *************************\n",
      "Loaded 184700 rows from drive/MyDrive/MIDS/w266/project/data/posptproc_corpus_spacy_s3_train_val.csv\n",
      "Loaded 20523 rows from drive/MyDrive/MIDS/w266/project/data/posptproc_corpus_spacy_s3_test.csv\n",
      "x-train shape: (162536,), x-val shape: (10000,), y-train shape: (162536,), y-val shape: (10000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddc00e09257486caeafdb12d3c6f042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b70f7a99a6e4f25ae06cd907335b142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffe4b2d93384a9e996880c6cb945af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69922bf0130340bba2ee011abc2a6768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a81cbcf8ac4f78943e1b518937916f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24363c0431f41bd812acff3f7a739bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8327816779384490b9c0c8863bcb0d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7620' max='7620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7620/7620 2:48:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.434900</td>\n",
       "      <td>1.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.243900</td>\n",
       "      <td>1.254261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.121300</td>\n",
       "      <td>1.201115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 10086.05\n",
      "Samples/second: 48.34\n",
      "Utilization after training: \n",
      "CPU RAM Used: 8.2 GB\n",
      "CPU RAM Free: 80.5 GB\n",
      "GPU memory occupied: 31741 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 3.7 GB\n",
      "Cached:    29.2 GB\n",
      "Utilization after post training cleanup: \n",
      "CPU RAM Used: 7.7 GB\n",
      "CPU RAM Free: 81.0 GB\n",
      "GPU memory occupied: 1819 MB.\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "*************************Training took 10086.063322544098 seconds *************************\n",
      "CPU times: user 2h 8min 8s, sys: 47min 5s, total: 2h 55min 14s\n",
      "Wall time: 2h 48min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'{\"*\"*25}Training model OPT on S3 {\"*\"*25}')\n",
    "train(get_config('opt', 's3'), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ILWFzRS0a6lf",
   "metadata": {
    "id": "ILWFzRS0a6lf"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ueuny-nWmRj",
   "metadata": {
    "id": "9ueuny-nWmRj"
   },
   "outputs": [],
   "source": [
    "tuning_configs = common.create_configs(GDRIVE_BASE, None, None, None, None)\n",
    "\n",
    "# # Final test list for model trained against s2 dataset.\n",
    "# FINAL_TEST_LIST = ['Princess Leia lay upon her bed all the night. She could not sleep at all.',\n",
    "#                    'He stopped himself for a minute and thought if it was the right thing to do. It did seem like a good thing to do.',\n",
    "#                    'There once lived king named Rama. He was very wise and just.',\n",
    "#                    'Once upon a time, an old owl lived in the forest. He was very wise.']\n",
    "\n",
    "# Final test list for model trained against s1 dataset.\n",
    "FINAL_TEST_LIST = ['Princess Leia lay upon her bed all the night.',\n",
    "                   'He stopped himself for a minute and thought if it was the right thing to do.',\n",
    "                   'There once lived king named Rama.',\n",
    "                   'Once upon a time, an old owl lived in the forest.']\n",
    "\n",
    "def generate_next_line(model_family, model, tokenizer, lines, prompt, device, viz=False):\n",
    "  transformers.logging.set_verbosity_error()\n",
    "  for i, test_input_text in enumerate(lines):\n",
    "      test_inputs = tokenizer([prompt + test_input_text], return_tensors='pt')\n",
    "      if model_family == 't5':\n",
    "        test_outputs = model.generate(\n",
    "            test_inputs['input_ids'].to(device),\n",
    "            num_beams=5,\n",
    "            no_repeat_ngram_size=3,\n",
    "            num_return_sequences=5,\n",
    "            max_new_tokens=100,\n",
    "            do_sample=True,\n",
    "            top_k=0,\n",
    "            return_dict_in_generate=True,\n",
    "            output_attentions=True)\n",
    "        test_output_ids = test_outputs['sequences']\n",
    "        print(test_outputs.keys())\n",
    "      else:\n",
    "        test_outputs = model.generate(\n",
    "          test_inputs['input_ids'].to(device),\n",
    "          num_beams=4,\n",
    "          no_repeat_ngram_size=2,\n",
    "          num_return_sequences=3,\n",
    "          max_length = 50,\n",
    "          do_sample=True,\n",
    "          top_k=0,\n",
    "          early_stopping=True,\n",
    "          return_dict_in_generate=True,\n",
    "          output_attentions=True\n",
    "        )\n",
    "        test_output_ids = test_outputs['sequences']\n",
    "\n",
    "      decoded = [tokenizer.decode(out_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).replace('\\n', ' ') for out_ids in test_output_ids]\n",
    "      if viz:\n",
    "        out = model(**test_inputs, decoder_input_ids=test_output_ids, output_attentions=True, return_dict=True)\n",
    "\n",
    "        encoder_text = tokenizer.convert_ids_to_tokens(test_inputs['input_ids'][0])\n",
    "        decoder_text = tokenizer.convert_ids_to_tokens(test_output_ids[0])\n",
    "        encoder_attentions = out.encoder_attentions\n",
    "        cross_attentions = out.cross_attentions\n",
    "        decoder_attentions = out.decoder_attentions\n",
    "        # encoder_attentions = test_outputs['encoder_attentions']\n",
    "        # decoder_attentions = test_outputs['decoder_attentions']\n",
    "        # cross_attentions = test_outputs['cross_attentions']        \n",
    "        print(f\"{len(encoder_attentions) = }\")\n",
    "        print(f\"{len(cross_attentions) = }\")\n",
    "        print(f\"{len(decoder_attentions) = }\")          \n",
    "        model_view(\n",
    "          cross_attention = cross_attentions[0],\n",
    "          encoder_attention = encoder_attentions,\n",
    "          decoder_attention = decoder_attentions,\n",
    "          encoder_tokens = encoder_text,\n",
    "          decoder_tokens = decoder_text)\n",
    "        \n",
    "      print(f'Input: {test_input_text}')\n",
    "      decoded = '\\n\\t'.join(decoded)\n",
    "      print(f'Output: {decoded}')\n",
    "\n",
    "def generate_for(config, device, viz=False):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "  print('*' *50)\n",
    "  print(f'Evaluating {config.model_name} tuned on {config.dataset} dataset')\n",
    "  # model = AutoModel.from_pretrained(config.tuned_model_path, output_attentions=(config.model_family == 't5')).to(device)\n",
    "  if config.model_family == 't5':\n",
    "    model = T5ForConditionalGeneration.from_pretrained(config.tuned_model_path).to(device)\n",
    "  else:\n",
    "    model = OPTForCausalLM.from_pretrained(config.model_name).to(device)  \n",
    "  generate_next_line(config.model_family, model, tokenizer, [FINAL_TEST_LIST[0]], config.prompt, device, viz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dOsRnXvJMY5C",
   "metadata": {
    "id": "dOsRnXvJMY5C"
   },
   "outputs": [],
   "source": [
    "## Untrained T5 model\n",
    "# evaluate(T5ForConditionalGeneration.from_pretrained(\"t5-large\").cuda(), t5_tokenizer, FINAL_TEST_LIST, \"Continue the next sentence of the story: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wxim_UyuNkF1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11847,
     "status": "ok",
     "timestamp": 1680993052461,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "wxim_UyuNkF1",
    "outputId": "cdb048c4-c632-480b-db20-75e0daf8efcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Evaluating google/t5-v1_1-base tuned on s2 dataset\n",
      "odict_keys(['sequences', 'encoder_attentions', 'decoder_attentions', 'cross_attentions'])\n",
      "Input: Princess Leia lay upon her bed all the night.\n",
      "Output: She sat down and slept.\n",
      "\tShe had been scolded by her mother, who had been so cruel to her that she could not bear it any longer.\n",
      "\tThen she woke up and went to the palace, where she saw a beautiful princess sitting on a throne, with a black robe on her head and a golden crown on her forehead.\n",
      "\tShe had slept a long time, and was very tired.\n",
      "\tShe was very frightened, and shook her head.\n"
     ]
    }
   ],
   "source": [
    "generate_for(tuning_configs['t5_s2'], torch.device(\"cuda\"), viz=False)\n",
    "\n",
    "# for name, config in tuning_configs.items():\n",
    "#   evaluate_with_config(config, device, viz=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VDCj9ff_-WMh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6211,
     "status": "ok",
     "timestamp": 1681009509158,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "VDCj9ff_-WMh",
    "outputId": "6c68e42a-0603-47f4-a6b7-87cf55edb365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Evaluating facebook/opt-350m tuned on s3 dataset\n",
      "Input: Princess Leia lay upon her bed all the night.\n",
      "Output: Princess Leia lay upon her bed all the night. She didn't sleep all night, she went to sleep in her room, but she woke up at 5: 00 a. m. to go to the bathroom to wash her hair.\n",
      "\tPrincess Leia lay upon her bed all the night. She must have been so tired.\n",
      "\tPrincess Leia lay upon her bed all the night. I'm not sure if you're being serious or not, but I'm pretty sure that's not true.\n"
     ]
    }
   ],
   "source": [
    "generate_for(tuning_configs['opt_s3'], torch.device(\"cuda\"), viz=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JEehci80VwgX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656,
     "output_embedded_package_id": "1LUzsgeQayRtzHkSGjjz1GHl_YHmEeEeO"
    },
    "executionInfo": {
     "elapsed": 13477,
     "status": "ok",
     "timestamp": 1680998408466,
     "user": {
      "displayName": "Ram S",
      "userId": "17279396566363655986"
     },
     "user_tz": 420
    },
    "id": "JEehci80VwgX",
    "outputId": "2e762538-21e9-46ed-f9b5-0ae222fa1dc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test():\n",
    "  # Reference: https://www.aclweb.org/anthology/P19-3007.pdf\n",
    "  tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "  config = tuning_configs['t5_s2']\n",
    "  # model = AutoModel.from_pretrained(config.tuned_model_path, output_attentions=True) \n",
    "  model = T5ForConditionalGeneration.from_pretrained(config.tuned_model_path)\n",
    "\n",
    "  inputs = tokenizer(\n",
    "      f\"{config.prompt}{FINAL_TEST_LIST[0]}\",\n",
    "      return_tensors=\"pt\",\n",
    "  )\n",
    "  encoder_input_ids = inputs.input_ids\n",
    "\n",
    "  output = model.generate(**inputs, return_dict_in_generate=True, output_attentions=True)\n",
    "  sequences = output.sequences\n",
    "  decoder_input_ids = sequences\n",
    "\n",
    "  out = model(**inputs, decoder_input_ids=sequences, output_attentions=True, return_dict=True)\n",
    "  encoder_attentions = out.encoder_attentions\n",
    "  cross_attentions = out.cross_attentions\n",
    "  decoder_attentions = out.decoder_attentions\n",
    "\n",
    "  decoded = [tokenizer.decode(out_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).replace('\\n', ' ') for out_ids in sequences]\n",
    "  print(f'Output: {decoded}')\n",
    "  encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n",
    "  decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])\n",
    "\n",
    "  # model_view(\n",
    "  #     cross_attention = cross_attentions,\n",
    "  #     encoder_attention = encoder_attentions, \n",
    "  #     decoder_attention = decoder_attentions,\n",
    "  #     encoder_tokens = encoder_text,\n",
    "  #     decoder_tokens = decoder_text)  \n",
    "  head_view(\n",
    "      cross_attention = cross_attentions,\n",
    "      encoder_attention = encoder_attentions, \n",
    "      decoder_attention = decoder_attentions,\n",
    "      encoder_tokens = encoder_text,\n",
    "      decoder_tokens = decoder_text)\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1qH9or9UvtJOb_mlSSHcRjZKwZT9uDwbl",
     "timestamp": 1680142704332
    }
   ]
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

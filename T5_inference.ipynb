{"cells":[{"cell_type":"markdown","source":["# T5 Tuned - Inference"],"metadata":{"id":"wHUaO6-oCKak"},"id":"wHUaO6-oCKak"},{"cell_type":"markdown","source":["## Install Dependencies"],"metadata":{"id":"97nY_nL9CeiJ"},"id":"97nY_nL9CeiJ"},{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"egOvt-Oq0M2J","executionInfo":{"status":"ok","timestamp":1680317347268,"user_tz":420,"elapsed":16055,"user":{"displayName":"Ram S","userId":"17279396566363655986"}},"outputId":"f20567de-d686-4905-f47c-fd8faa14616b"},"id":"egOvt-Oq0M2J","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"markdown","source":["## Connect to Google Drive\n","We will be loading data from google drive and also save trained models to google drive. So lets mount google drive."],"metadata":{"id":"RtUED7nKSww0"},"id":"RtUED7nKSww0"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DvSvLEFgSxWH","executionInfo":{"status":"ok","timestamp":1680317393068,"user_tz":420,"elapsed":24859,"user":{"displayName":"Ram S","userId":"17279396566363655986"}},"outputId":"7d6ecc11-809f-4f8b-bb04-ba441efc52a2"},"id":"DvSvLEFgSxWH","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Imports and Constants"],"metadata":{"id":"5QyOXIFTC1kO"},"id":"5QyOXIFTC1kO"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","from sklearn.model_selection import train_test_split\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import torch\n","import transformers\n","from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from collections import deque\n","\n","DATA_NAME = \"s2\"\n","# T5_MODEL_NAME = \"t5-small\"\n","T5_MODEL_NAME = \"t5-base\"\n","\n","TUNED_T5_SAVED = f'drive/MyDrive/MIDS/w266/project/saved_models/{T5_MODEL_NAME}-data{DATA_NAME}-finetuned'\n","PROMPT = 'Generate next line: '\n","\n","FINAL_TEST_LIST = ['Princess Leia lay upon her bed all the night.',\n","                   'He stopped himself for a minute and thought if it was the right thing to do.',\n","                   'There once lived king named Rama.',\n","                   'Once upon a time, an old Owl lived in the forest.']"],"metadata":{"id":"iyD4NJOTDDlt","executionInfo":{"status":"ok","timestamp":1680317408711,"user_tz":420,"elapsed":6396,"user":{"displayName":"Ram S","userId":"17279396566363655986"}}},"id":"iyD4NJOTDDlt","execution_count":3,"outputs":[]},{"cell_type":"code","source":["t5_tokenizer = T5Tokenizer.from_pretrained(T5_MODEL_NAME)"],"metadata":{"id":"fw6I0qfQ0U5z","executionInfo":{"status":"ok","timestamp":1680317412427,"user_tz":420,"elapsed":1440,"user":{"displayName":"Ram S","userId":"17279396566363655986"}},"colab":{"base_uri":"https://localhost:8080/","height":208,"referenced_widgets":["db0ed14e1d214f8ab82b8c0d4d394f0f","eadac6467adb424a807ae40b65111ef4","6a574aa5135c4a23a5161cb1b8bf803b","429d207dc2184ad79cdc19b80046eae6","434c57c5a435440d9e4828479e50dc79","ea800ecebcff407c9e9b34c03007b5d5","aa34dac413e24998bec57805feb296d7","6d00f9c394f04b35a5b68af26d28bc50","6f33190a37514f5583d73717f7d5bb5f","d590e12dc5944732bffba9a4c4fa818b","8198bb3757ec42058a5c495522ba94d1","a8828dc99f264acca78fd4936a9412b2","8a249a6c53aa4c6bb3a1231af5ee9ed1","3fae65577ffc4c1dbc3cd23f122e6630","64aec839c8f74a4085fde3dd468446dd","0926a1c9bb86460b8dc57990ce4a90e6","f84bc417c0f44529b440d535feba0d6d","65e9dfee7f0347e39294e15f2ca19f18","e9c34341c68a42cd88ae9fc5575c7b1a","4a4905546a1d42afbd226bd1e410fe42","f870c55bd29149d19b2536f6319b0a50","6a4667526bbd4e35980707759ad80d50"]},"outputId":"af62f269-0c2c-49d6-ad0f-7d51ab0bc872"},"id":"fw6I0qfQ0U5z","execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db0ed14e1d214f8ab82b8c0d4d394f0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8828dc99f264acca78fd4936a9412b2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"UBU7IM3uc14g"},"id":"UBU7IM3uc14g"},{"cell_type":"code","source":["class Inferencer:\n","  def __init__(self, model, tokenizer, prompt='', max_new_tokens=100, tensor_type='pt', num_beams=3):\n","    self.model = model\n","    self.tokenizer = tokenizer\n","    self.prompt = prompt\n","    self.max_new_tokens = max_new_tokens\n","    self.tensor_type = tensor_type\n","    self.num_beams = num_beams\n","\n","  def __call__(self, context_lines):\n","    transformers.logging.set_verbosity_error()\n","    test_inputs = self.tokenizer([self.prompt + ' '.join(context_lines)], return_tensors=self.tensor_type)\n","    test_output_ids = model.generate(\n","        test_inputs['input_ids'].cuda(),\n","        num_beams=self.num_beams,\n","        no_repeat_ngram_size=2,\n","        num_return_sequences=self.num_beams,\n","        max_new_tokens=self.max_new_tokens,\n","        do_sample=True,\n","        top_k=0)\n","    decoded = [self.tokenizer.decode(out_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False) for out_ids in test_output_ids]\n","    return decoded\n"],"metadata":{"id":"9WyuXHzJUTSY","executionInfo":{"status":"ok","timestamp":1680317419820,"user_tz":420,"elapsed":116,"user":{"displayName":"Ram S","userId":"17279396566363655986"}}},"id":"9WyuXHzJUTSY","execution_count":5,"outputs":[]},{"cell_type":"code","source":["class StoryBot:\n","  \"\"\"Class to mimic a bot that continues the story.\"\"\"\n","  def __init__(self, inferencer, n_iters=20, lines_to_use=1):\n","    self._n_iters = n_iters\n","    self.lines_to_use = lines_to_use\n","    self.inferencer = inferencer\n","    self.re_init()\n","\n","  def re_init(self):\n","    self.story = []\n","    self.context_lines = deque([], self.lines_to_use)\n","\n","  def get_user_choice(self):\n","    output_lines = self.inferencer(self.context_lines)\n","    if len(output_lines) > 1:\n","      print('Choose the line of your choice:')\n","      for i, line in enumerate(output_lines):\n","        print(f'{i}:', line)\n","      print(f'{i+1}: Regenerate')\n","      print(f'{i+2}: End')\n","      user_opt = -1\n","      while user_opt == -1:\n","        try:\n","            user_input = input('Input the number of your choice (or ): ')\n","            user_opt = int(user_input)\n","            if user_opt < len(output_lines):\n","              return output_lines[user_opt]\n","            elif user_opt == len(output_lines):\n","              return 'regenerate'\n","            elif user_opt == len(output_lines) + 1:\n","              return 'end'\n","        except ValueError:\n","            user_opt = -1\n","    else:\n","      return output_lines[0]\n","\n","  def print_story(self):\n","    for i, line in enumerate(self.story):\n","      if i%2 == 0:\n","        print(f'User: {line}') \n","      else:\n","        print(f'Generated: {line}') \n","\n","  def run(self):\n","    print('*'*50)\n","    print('Welcome to StoryBot!\\n')\n","    print('This program simulates an MMS kind of interaction with a bot to create a story sequentially.')\n","    print('When the prompt appears below, start typing as if it were the input on your mobile.')\n","    print('Enter end to end the story and restart to restart.') \n","    print('*'*50, '\\n')\n","    restart = False\n","    i = 0\n","    while i < self._n_iters:\n","      if i > 0:\n","        print('The story so far:')\n","        self.print_story()\n","      i = i + 1\n","      # get the sentence from the user\n","      sentence_in = input('Enter next line (or end): ').strip()\n","      # accomodate special prompts\n","      if sentence_in == 'end':\n","        break\n","      if sentence_in == 'restart':\n","        i = 0\n","        self.re_init()\n","        continue\n","      self.context_lines.append(sentence_in)\n","      self.story.append(sentence_in)\n","      output = 'regenerate'\n","      while output == 'regenerate':\n","        output = self.get_user_choice()\n","      if output == 'end':\n","        break\n","      self.context_lines.append(output)\n","      self.story.append(output)\n","\n","    print()\n","    print('\\n======== Final story: =========\\n')\n","    self.print_story()\n","\n"],"metadata":{"id":"2r-E3q4xCa4z","executionInfo":{"status":"ok","timestamp":1680323159353,"user_tz":420,"elapsed":122,"user":{"displayName":"Ram S","userId":"17279396566363655986"}}},"id":"2r-E3q4xCa4z","execution_count":29,"outputs":[]},{"cell_type":"code","source":["tokenizer = T5Tokenizer.from_pretrained(T5_MODEL_NAME)\n","model = T5ForConditionalGeneration.from_pretrained(TUNED_T5_SAVED).cuda()\n"],"metadata":{"id":"2NZCLlzNxAII"},"id":"2NZCLlzNxAII","execution_count":null,"outputs":[]},{"cell_type":"code","source":["inferencer = Inferencer(model, tokenizer, prompt=PROMPT)\n","story_bot = StoryBot(inferencer, n_iters=10, lines_to_use=5)\n","story_bot.run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BOPjAniJPRPW","executionInfo":{"status":"ok","timestamp":1680323363874,"user_tz":420,"elapsed":201561,"user":{"displayName":"Ram S","userId":"17279396566363655986"}},"outputId":"6e9d4126-22fa-48cd-b57e-f50357e01bf1"},"id":"BOPjAniJPRPW","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["**************************************************\n","Welcome to StoryBot!\n","\n","This program simulates an MMS kind of interaction with a bot to create a story sequentially.\n","When the prompt appears below, start typing as if it were the input on your mobile.\n","Enter end to end the story and restart to restart.\n","************************************************** \n","\n","Enter next line (or end): There was a farmer who had a dog.\n","Choose the line of your choice:\n","0: He had a dog, and he was very polite.\n","1: He was a dog, and he was very fond of dogs.\n","2: He had a dog, and he was very proud of it.\n","3: Regenerate\n","4: End\n","Input the number of your choice (or ): 1\n","The story so far:\n","User: There was a farmer who had a dog.\n","Generated: He was a dog, and he was very fond of dogs.\n","Enter next line (or end): He had multiple dogs of the same breed\n","Choose the line of your choice:\n","0: He had a dog, and he was very fond of dogs.\n","1: He had a lot of dogs, and he liked to have them.\n","2: He had a dog, and he was very fond of dogs.\n","3: Regenerate\n","4: End\n","Input the number of your choice (or ): 1\n","The story so far:\n","User: There was a farmer who had a dog.\n","Generated: He was a dog, and he was very fond of dogs.\n","User: He had multiple dogs of the same breed\n","Generated: He had a lot of dogs, and he liked to have them.\n","Enter next line (or end): His name was Ramachandran Senthamarai\n","Choose the line of your choice:\n","0: He had a dog, and he was very fond of dogs.\n","1: He had a dog, and he was very fond of dogs.\n","2: He had a dog of the same breed, and he liked to have them.\n","3: Regenerate\n","4: End\n","Input the number of your choice (or ): 2\n","The story so far:\n","User: There was a farmer who had a dog.\n","Generated: He was a dog, and he was very fond of dogs.\n","User: He had multiple dogs of the same breed\n","Generated: He had a lot of dogs, and he liked to have them.\n","User: His name was Ramachandran Senthamarai\n","Generated: He had a dog of the same breed, and he liked to have them.\n","Enter next line (or end): restart\n","Enter next line (or end): One day Anya went to her parents and told them she wanted icecream.\n","Choose the line of your choice:\n","0: Then she told them she wanted ice cream.\n","1: Then she went to the door and said, “I want ice cream.”\n","2: She said, “I want ice cream, but I don't want to eat it.”\n","3: Regenerate\n","4: End\n","Input the number of your choice (or ): 3\n","Choose the line of your choice:\n","0: She said, \"It's ice cream!\"\n","1: Then she said, “I have never had ice cream before.”\n","2: \"It's ice cream,\" she said.\n","3: Regenerate\n","4: End\n","Input the number of your choice (or ): 1\n","The story so far:\n","User: One day Anya went to her parents and told them she wanted icecream.\n","Generated: Then she said, “I have never had ice cream before.”\n","Enter next line (or end): Her parents told her that it was too cold for icecream.\n","Choose the line of your choice:\n","0: When she went to her parents, she said, “I have never had ice cream before.”\n","1: They said, “I have never had ice cream before.”\n","2: “It is too cold for ice cream,” said Anya.\n","3: Regenerate\n","4: End\n","Input the number of your choice (or ): 3\n","Choose the line of your choice:\n","0: But she did not want ice cream.\n","1: Then she said, “I have never had ice cream before.”\n","2: They said, “It is too cold for ice cream.”\n","3: Regenerate\n","4: End\n","Input the number of your choice (or ): 4\n","\n","\n","======== Final story: =========\n","\n","User: One day Anya went to her parents and told them she wanted icecream.\n","Generated: Then she said, “I have never had ice cream before.”\n","User: Her parents told her that it was too cold for icecream.\n"]}]},{"cell_type":"code","source":["def evaluate(model, tokenizer, lines, prompt, contrastive=True):\n","  transformers.logging.set_verbosity_error()\n","  for test_input_text in lines:\n","      test_inputs = tokenizer([prompt + test_input_text], return_tensors='pt')\n","      if contrastive:\n","        test_output_ids = model.generate(\n","            test_inputs['input_ids'].cuda(), \n","            penalty_alpha=0.4, top_k=5, max_length=256)\n","      else:\n","        test_output_ids = model.generate(\n","            test_inputs['input_ids'].cuda(),\n","            num_beams=5,\n","            no_repeat_ngram_size=2,\n","            num_return_sequences=5,\n","            max_new_tokens=100,\n","            do_sample=True,\n","            top_k=0)\n","      print(f'Input: {test_input_text}')\n","      decoded = [tokenizer.decode(out_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False) for out_ids in test_output_ids]\n","      print(f'Output: {decoded}')"],"metadata":{"id":"fV2GYVEqIrQ8","executionInfo":{"status":"ok","timestamp":1680310345496,"user_tz":420,"elapsed":219,"user":{"displayName":"Ram S","userId":"17279396566363655986"}}},"id":"fV2GYVEqIrQ8","execution_count":25,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iJvegk-rK13d","executionInfo":{"status":"ok","timestamp":1680308928818,"user_tz":420,"elapsed":3852,"user":{"displayName":"Ram S","userId":"17279396566363655986"}}},"id":"iJvegk-rK13d","execution_count":16,"outputs":[]},{"cell_type":"code","source":["def infer_nextline(model, tokenizer, lines, prompt, contrastive=True):\n","  transformers.logging.set_verbosity_error()\n","  for test_input_text in lines:\n","      test_inputs = tokenizer([prompt + test_input_text], return_tensors='pt')\n","      if contrastive:\n","        test_output_ids = model.generate(\n","            test_inputs['input_ids'].cuda(), \n","            penalty_alpha=0.4, top_k=5, max_length=256)\n","      else:\n","        test_output_ids = model.generate(\n","            test_inputs['input_ids'].cuda(),\n","            num_beams=5,\n","            no_repeat_ngram_size=2,\n","            num_return_sequences=5,\n","            max_new_tokens=100,\n","            do_sample=True,\n","            top_k=0)\n","      print(f'Input: {test_input_text}')\n","      decoded = [tokenizer.decode(out_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False) for out_ids in test_output_ids]\n","      print(f'Output: {decoded}')"],"metadata":{"id":"jFD-hJKQTnHd"},"id":"jFD-hJKQTnHd","execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"v_ssk_8gJwaK","executionInfo":{"status":"ok","timestamp":1680308928819,"user_tz":420,"elapsed":17,"user":{"displayName":"Ram S","userId":"17279396566363655986"}}},"id":"v_ssk_8gJwaK","execution_count":17,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":586},"id":"IifRfl0cNOw6","executionInfo":{"status":"error","timestamp":1680308934509,"user_tz":420,"elapsed":3383,"user":{"displayName":"Ram S","userId":"17279396566363655986"}},"outputId":"2bf55d6e-9b07-498e-fbc1-b80f1db45052"},"id":"IifRfl0cNOw6","execution_count":18,"outputs":[{"name":"stdout","output_type":"stream","text":["**************************************************\n","Welcome to StoryBot!\n","\n","This program simulates an MMS kind of interaction with a bot to create a story sequentially.\n","When the prompt appears below, start typing as if it were the input on your mobile.\n","\n","See the following special prompts:\n","1) opts: Model will give you 3 options to choose from (takes longer to generate)\n","2) gocrazy: Running out of ideas? Give the story an unexpected twist (not always make sense)\n","3) readstory: Print the full story\n","4) endstory: Print the story and finish the program\n","************************************************** \n","\n","Once upon a time, an old Owl lived in the forest.\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-075c3a60ef93>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstory_bot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-1a4a26ce95b2>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mstory_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstory_prompt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0;31m# generate output (can make it multi-thread to make it go faster)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo_crazy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         outputs = [\n","\u001b[0;32m<ipython-input-15-1a4a26ce95b2>\u001b[0m in \u001b[0;36m_generate_output\u001b[0;34m(self, input_tokens, go_crazy, creative, nbeams, mnt, nrng)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         model_output = self.model.generate(\n\u001b[0;32m---> 41\u001b[0;31m               \u001b[0minput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m               \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbeams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m               \u001b[0mno_repeat_ngram_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnrng\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"]}]},{"cell_type":"code","source":["## Fine tuned T5 model\n","print(\"==== Contrastive Search ====\")\n","evaluate(model, t5_tokenizer, FINAL_TEST_LIST, PROMPT, contrastive=True)\n","\n","print(\"==== Beam Search ====\")\n","evaluate(model, t5_tokenizer, FINAL_TEST_LIST, PROMPT, contrastive=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxim_UyuNkF1","executionInfo":{"status":"ok","timestamp":1680224027940,"user_tz":420,"elapsed":48960,"user":{"displayName":"Ram S","userId":"17279396566363655986"}},"outputId":"63e705c4-e5ac-4ff2-def4-47b665f813d7"},"id":"wxim_UyuNkF1","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==== Contrastive Search ====\n","Input: Princess Leia lay upon her bed all the night.\n","Output: ['She slept in a slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering, slumbering']\n","Input: He stopped himself for a minute and thought if it was the right thing to do.\n","Output: ['“It is a good thing to do,” said he, “and I am sure you will be able to do it.”']\n","Input: There once lived king named Rama.\n","Output: ['He was a great king, and he was the most powerful.']\n","Input: Once upon a time, an old Owl lived in the forest.\n","Output: ['He sat on a tree, and he sat down to eat the berries.']\n","==== Beam Search ====\n","Input: Princess Leia lay upon her bed all the night.\n","Output: ['She was so tired that she could not sleep.', 'She was so dreadful that she felt as if she had lost her way, and she did not know what to do.', 'Then she went to sleep, and when she had woken up, she sat down in the corner of the bed.', 'Then she sat down and cried, “It’s a good night, Princess Leia!”', 'Then she woke up in the middle of the night.']\n","Input: He stopped himself for a minute and thought if it was the right thing to do.\n","Output: ['\"It\\'s the right thing to do,\" he said.', '“It is a good thing to do,” he said.', 'And he said, “It is a good thing to do.', '“It is a great deal of work to do,” said he.', '“Well, if it was a right thing to do,” he said.']\n","Input: There once lived king named Rama.\n","Output: ['He was a king of the gods.', 'Rama was a very good man, and he was very wise.', 'Rama was a king of the desert.', 'Rama was a great king, and he ruled over all the world.', 'He was a king, and he commanded all his people to obey him.']\n","Input: Once upon a time, an old Owl lived in the forest.\n","Output: ['He had a great deal of money, and he was very good to him.', 'He was a frog, and he lived in an old hut.', 'He was very poor, but he was not a good one, and did not like to be scolded.', 'He was a good-natured creature.', 'He had a great deal of money, and he had lots of time to spare.']\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"6TUt1hxpKvDW"},"id":"6TUt1hxpKvDW"},{"cell_type":"code","source":["evaluate(model, t5_tokenizer, ['A rich old farmer, who felt that he had not many more days to live, called his sons to his bedside.'], PROMPT, contrastive=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFX3MIARK7hh","executionInfo":{"status":"ok","timestamp":1680310367160,"user_tz":420,"elapsed":4241,"user":{"displayName":"Ram S","userId":"17279396566363655986"}},"outputId":"d16d6d28-a900-4126-82fd-e51e84a6b7ab"},"id":"kFX3MIARK7hh","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: A rich old farmer, who felt that he had not many more days to live, called his sons to his bedside.\n","Output: ['They sat down on a bed, and looked at each other.', 'They said to him, “It is a good thing that thou shalt not die.”', '\"I am a farmer,\" he said, \"and I do not know what to do with my sons.\"', 'The sons of the poor farmer were very happy, but they did not want to see him, and so he gave them a supper.', 'The sons sat in the bed, and cried out: \"Let us go to bed.\"']\n"]}]},{"cell_type":"code","source":["evaluate(model, t5_tokenizer, ['Then he sat down and talked to his sons.'], PROMPT, contrastive=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2obsxS6BTQtR","executionInfo":{"status":"ok","timestamp":1680226510883,"user_tz":420,"elapsed":3102,"user":{"displayName":"Ram S","userId":"17279396566363655986"}},"outputId":"4f5387c9-444b-494b-ad7a-a4afb383fa59"},"id":"2obsxS6BTQtR","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: Then he sat down and talked to his sons.\n","Output: ['\"I don\\'t know,\" said he.', 'Then he sat down and talked to them.', 'Then he said to his sons, “I am very sorry for you, but I don’t know what to do with you.”', '\"It\\'s a good thing,\" he said.', '\"What do you think?\" asked he.']\n"]}]},{"cell_type":"code","source":["story_bot = GPTStoryBot()\n","story_bot.run()"],"metadata":{"id":"iqMMiBfCCla_"},"id":"iqMMiBfCCla_","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Round 1\n","\n","**Prompt**: Once upon a time, an old Owl lived in the forest.\n","\n","**Response**: He was a good-natured creature.\n","\n","**Prompt**: The owl helped all animals that came to him.\n","\n","**Response**: The owl was a very good man, and he was very kind to the animals that came to him.\n","\n","**Prompt**: One day a little mouse came to the owl.\n","\n","**Response**: The little mouse sat down and looked at the owl.\n","\n","**Prompt**: The owl saw that the mouse was very sad.\n","\n","**Response**: The owl said, “It is a very sad mouse.\"\n","\n","**Prompt**: The owl asked \"why are you so sad, mouse?\"\n","\n","**Response**: \"It\\'s a misfortune,\" answered the mouse.\n","\n","## Round 2\n","**Prompt**: A rich old farmer, who felt that he had not many more days to live, called his sons to his bedside.\n","**Response**: "],"metadata":{"id":"zLsxWvfmP-IW"},"id":"zLsxWvfmP-IW"},{"cell_type":"code","source":[],"metadata":{"id":"vsV697tcRxsM"},"id":"vsV697tcRxsM","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1qH9or9UvtJOb_mlSSHcRjZKwZT9uDwbl","timestamp":1680142704332}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"db0ed14e1d214f8ab82b8c0d4d394f0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eadac6467adb424a807ae40b65111ef4","IPY_MODEL_6a574aa5135c4a23a5161cb1b8bf803b","IPY_MODEL_429d207dc2184ad79cdc19b80046eae6"],"layout":"IPY_MODEL_434c57c5a435440d9e4828479e50dc79"}},"eadac6467adb424a807ae40b65111ef4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea800ecebcff407c9e9b34c03007b5d5","placeholder":"​","style":"IPY_MODEL_aa34dac413e24998bec57805feb296d7","value":"Downloading (…)ve/main/spiece.model: 100%"}},"6a574aa5135c4a23a5161cb1b8bf803b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d00f9c394f04b35a5b68af26d28bc50","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f33190a37514f5583d73717f7d5bb5f","value":791656}},"429d207dc2184ad79cdc19b80046eae6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d590e12dc5944732bffba9a4c4fa818b","placeholder":"​","style":"IPY_MODEL_8198bb3757ec42058a5c495522ba94d1","value":" 792k/792k [00:00&lt;00:00, 5.38MB/s]"}},"434c57c5a435440d9e4828479e50dc79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea800ecebcff407c9e9b34c03007b5d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa34dac413e24998bec57805feb296d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d00f9c394f04b35a5b68af26d28bc50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f33190a37514f5583d73717f7d5bb5f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d590e12dc5944732bffba9a4c4fa818b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8198bb3757ec42058a5c495522ba94d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8828dc99f264acca78fd4936a9412b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a249a6c53aa4c6bb3a1231af5ee9ed1","IPY_MODEL_3fae65577ffc4c1dbc3cd23f122e6630","IPY_MODEL_64aec839c8f74a4085fde3dd468446dd"],"layout":"IPY_MODEL_0926a1c9bb86460b8dc57990ce4a90e6"}},"8a249a6c53aa4c6bb3a1231af5ee9ed1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f84bc417c0f44529b440d535feba0d6d","placeholder":"​","style":"IPY_MODEL_65e9dfee7f0347e39294e15f2ca19f18","value":"Downloading (…)lve/main/config.json: 100%"}},"3fae65577ffc4c1dbc3cd23f122e6630":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9c34341c68a42cd88ae9fc5575c7b1a","max":1208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a4905546a1d42afbd226bd1e410fe42","value":1208}},"64aec839c8f74a4085fde3dd468446dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f870c55bd29149d19b2536f6319b0a50","placeholder":"​","style":"IPY_MODEL_6a4667526bbd4e35980707759ad80d50","value":" 1.21k/1.21k [00:00&lt;00:00, 39.4kB/s]"}},"0926a1c9bb86460b8dc57990ce4a90e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f84bc417c0f44529b440d535feba0d6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65e9dfee7f0347e39294e15f2ca19f18":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9c34341c68a42cd88ae9fc5575c7b1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a4905546a1d42afbd226bd1e410fe42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f870c55bd29149d19b2536f6319b0a50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a4667526bbd4e35980707759ad80d50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}